#!/usr/bin/env python3
"""
ä¼šè­°è¦ç´„ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ (Issue #21å¯¾å¿œ)

è»½é‡LLMã‚’ä½¿ç”¨ã—ã¦å§”å“¡ä¼šä¼šè­°ã‚„æœ¬ä¼šè­°ã®è¦ç´„ã‚’è‡ªå‹•ç”Ÿæˆ
- å›½ä¼šè­°äº‹éŒ²ã®è¦ç´„ä½œæˆ
- ä¸»è¦è­°è«–ãƒã‚¤ãƒ³ãƒˆã®æŠ½å‡º
- ç™ºè¨€è€…åˆ¥ã®ä¸»å¼µè¦ç´„
- çµè«–ãƒ»æ±ºè­°äº‹é …ã®æ˜ç¢ºåŒ–

ä½¿ç”¨LLM: Ollama (ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ) ã¾ãŸã¯ OpenAI API (è¨­å®šã«ã‚ˆã‚Šé¸æŠ)
"""

import json
import re
import os
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging
from collections import defaultdict

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class MeetingSummaryGenerator:
    """ä¼šè­°è¦ç´„ç”Ÿæˆã‚¯ãƒ©ã‚¹ (Issue #21å¯¾å¿œ)"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.speeches_dir = self.project_root / "frontend" / "public" / "data" / "speeches"
        self.summaries_dir = self.project_root / "frontend" / "public" / "data" / "summaries"
        self.summaries_dir.mkdir(parents=True, exist_ok=True)
        
        # LLMè¨­å®š
        self.llm_type = os.getenv('LLM_TYPE', 'mock')  # 'ollama', 'openai', 'mock'
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        
        # è¦ç´„è¨­å®š
        self.max_input_length = 8000  # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®æœ€å¤§é•·
        self.summary_length = 500     # è¦ç´„ã®ç›®æ¨™æ–‡å­—æ•°
        
        # è»½é‡ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
        self.model_name = self._select_model()
        
    def _select_model(self) -> str:
        """ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ"""
        if self.llm_type == 'ollama':
            return 'llama3.2:3b'  # è»½é‡ãªæ—¥æœ¬èªå¯¾å¿œãƒ¢ãƒ‡ãƒ«
        elif self.llm_type == 'openai':
            return 'gpt-3.5-turbo'  # ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®è‰¯ã„ãƒ¢ãƒ‡ãƒ«
        else:
            return 'mock'  # ãƒ†ã‚¹ãƒˆç”¨ãƒ¢ãƒƒã‚¯
    
    def load_speech_data(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """è­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        logger.info("è­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        
        # æœ€æ–°ã®è­°äº‹éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
        speech_files = list(self.speeches_dir.glob("speeches_*.json"))
        if not speech_files:
            logger.error("è­°äº‹éŒ²ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return []
        
        # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
        latest_file = sorted(speech_files)[-1]
        logger.info(f"ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«: {latest_file}")
        
        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                speeches = data if isinstance(data, list) else data.get('data', [])
                
                if limit:
                    speeches = speeches[:limit]
                
                logger.info(f"èª­ã¿è¾¼ã¿å®Œäº†: {len(speeches)}ä»¶ã®ç™ºè¨€")
                return speeches
                
        except Exception as e:
            logger.error(f"è­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def group_speeches_by_meeting(self, speeches: List[Dict[str, Any]]) -> Dict[str, List[Dict[str, Any]]]:
        """ç™ºè¨€ã‚’ä¼šè­°åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–"""
        logger.info("ä¼šè­°åˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ä¸­...")
        
        meetings = defaultdict(list)
        
        for speech in speeches:
            # ä¼šè­°ã‚­ãƒ¼ã®ç”Ÿæˆ (æ—¥ä»˜ + å§”å“¡ä¼šå + é™¢)
            date = speech.get('date', 'unknown')
            committee = speech.get('committee', 'æœ¬ä¼šè­°')
            house = speech.get('house', 'unknown')
            
            meeting_key = f"{date}_{house}_{committee}"
            meetings[meeting_key].append(speech)
        
        # ç™ºè¨€æ•°ãŒå°‘ãªã„ä¼šè­°ã¯é™¤å¤–
        filtered_meetings = {
            key: speeches for key, speeches in meetings.items() 
            if len(speeches) >= 5
        }
        
        logger.info(f"å¯¾è±¡ä¼šè­°æ•°: {len(filtered_meetings)}ä»¶")
        return filtered_meetings
    
    def prepare_meeting_text(self, speeches: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ä¼šè­°ãƒ†ã‚­ã‚¹ãƒˆã‚’è¦ç´„ç”¨ã«æº–å‚™"""
        meeting_info = {
            'date': speeches[0].get('date', 'unknown'),
            'committee': speeches[0].get('committee', 'æœ¬ä¼šè­°'),
            'house': speeches[0].get('house', 'unknown'),
            'session': speeches[0].get('session', 'unknown'),
            'speech_count': len(speeches),
            'speakers': set(),
            'parties': set(),
            'full_text': '',
            'structured_text': []
        }
        
        # ç™ºè¨€ã‚’æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_speeches = sorted(speeches, key=lambda x: x.get('url', ''))
        
        full_text_parts = []
        for speech in sorted_speeches:
            speaker = speech.get('speaker', 'ä¸æ˜')
            party = speech.get('party', 'ä¸æ˜')
            text = speech.get('text', '')
            
            # çŸ­ã™ãã‚‹ç™ºè¨€ã¯é™¤å¤–
            if len(text.strip()) < 20:
                continue
            
            meeting_info['speakers'].add(speaker)
            meeting_info['parties'].add(party)
            
            # æ§‹é€ åŒ–ãƒ†ã‚­ã‚¹ãƒˆ
            speech_entry = {
                'speaker': speaker,
                'party': party,
                'text': text[:1000]  # é•·ã™ãã‚‹ç™ºè¨€ã¯åˆ¶é™
            }
            meeting_info['structured_text'].append(speech_entry)
            
            # å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆ
            full_text_parts.append(f"ã€{speaker}({party})ã€‘{text[:800]}")
        
        # å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆï¼ˆé•·ã•åˆ¶é™ï¼‰
        full_text = '\n\n'.join(full_text_parts)
        if len(full_text) > self.max_input_length:
            full_text = full_text[:self.max_input_length] + '...'
        
        meeting_info['full_text'] = full_text
        meeting_info['speakers'] = list(meeting_info['speakers'])
        # Noneå€¤ã‚’é™¤å¤–ã—ã¦æ”¿å…šãƒªã‚¹ãƒˆã‚’ä½œæˆ
        meeting_info['parties'] = [p for p in meeting_info['parties'] if p is not None]
        
        return meeting_info
    
    def generate_summary_with_llm(self, meeting_info: Dict[str, Any]) -> Dict[str, Any]:
        """LLMã‚’ä½¿ç”¨ã—ã¦è¦ç´„ã‚’ç”Ÿæˆ"""
        
        if self.llm_type == 'mock':
            return self._generate_mock_summary(meeting_info)
        elif self.llm_type == 'ollama':
            return self._generate_ollama_summary(meeting_info)
        elif self.llm_type == 'openai':
            return self._generate_openai_summary(meeting_info)
        else:
            logger.error(f"æœªå¯¾å¿œã®LLMã‚¿ã‚¤ãƒ—: {self.llm_type}")
            return self._generate_mock_summary(meeting_info)
    
    def _generate_mock_summary(self, meeting_info: Dict[str, Any]) -> Dict[str, Any]:
        """ãƒ¢ãƒƒã‚¯è¦ç´„ç”Ÿæˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        logger.info("ãƒ¢ãƒƒã‚¯è¦ç´„ç”Ÿæˆä¸­...")
        
        committee = meeting_info['committee']
        date = meeting_info['date']
        speaker_count = len(meeting_info['speakers'])
        speech_count = meeting_info['speech_count']
        parties = meeting_info['parties']
        
        # ç°¡å˜ãªçµ±è¨ˆãƒ™ãƒ¼ã‚¹è¦ç´„
        summary = {
            'title': f"{date} {committee}ä¼šè­°è¦ç´„",
            'overview': f"{date}ã«é–‹å‚¬ã•ã‚ŒãŸ{committee}ä¼šè­°ã§ã¯ã€{len(parties)}æ”¿å…šã‹ã‚‰{speaker_count}åã®è­°å“¡ãŒ{speech_count}å›ã®ç™ºè¨€ã‚’è¡Œã„ã¾ã—ãŸã€‚",
            'key_points': [
                f"ä¸»è¦å‚åŠ æ”¿å…š: {', '.join(parties[:3])}",
                f"ç™ºè¨€è€…æ•°: {speaker_count}å",
                f"ç·ç™ºè¨€å›æ•°: {speech_count}å›",
                "è©³ç´°ãªè­°è«–å†…å®¹ã¯å…ƒãƒ‡ãƒ¼ã‚¿ã‚’ã”å‚ç…§ãã ã•ã„ã€‚"
            ],
            'conclusion': "ä¼šè­°ã¯äºˆå®šé€šã‚Šé€²è¡Œã—ã€å„å…šã‹ã‚‰æ´»ç™ºãªè­°è«–ãŒè¡Œã‚ã‚Œã¾ã—ãŸã€‚",
            'participants': {
                'speakers': meeting_info['speakers'][:10],  # ä¸Šä½10å
                'parties': parties
            },
            'metadata': {
                'summary_type': 'mock',
                'model': 'statistical_analysis',
                'generated_at': datetime.now().isoformat()
            }
        }
        
        return summary
    
    def _generate_ollama_summary(self, meeting_info: Dict[str, Any]) -> Dict[str, Any]:
        """Ollama LLMã‚’ä½¿ç”¨ã—ãŸè¦ç´„ç”Ÿæˆ"""
        try:
            import requests
            
            prompt = self._create_summary_prompt(meeting_info)
            
            # Ollama APIå‘¼ã³å‡ºã—
            ollama_url = "http://localhost:11434/api/generate"
            payload = {
                "model": self.model_name,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.3,
                    "max_tokens": 1000
                }
            }
            
            response = requests.post(ollama_url, json=payload, timeout=60)
            response.raise_for_status()
            
            result = response.json()
            summary_text = result.get('response', '')
            
            return self._parse_llm_summary(summary_text, meeting_info, 'ollama')
            
        except Exception as e:
            logger.error(f"Ollamaè¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_mock_summary(meeting_info)
    
    def _generate_openai_summary(self, meeting_info: Dict[str, Any]) -> Dict[str, Any]:
        """OpenAI APIã‚’ä½¿ç”¨ã—ãŸè¦ç´„ç”Ÿæˆ"""
        try:
            import openai
            
            if not self.openai_api_key:
                logger.warning("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ¢ãƒƒã‚¯è¦ç´„ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")
                return self._generate_mock_summary(meeting_info)
            
            openai.api_key = self.openai_api_key
            prompt = self._create_summary_prompt(meeting_info)
            
            response = openai.ChatCompletion.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯å›½ä¼šè­°äº‹éŒ²ã®è¦ç´„ã‚’ç”Ÿæˆã™ã‚‹å°‚é–€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=1000,
                temperature=0.3
            )
            
            summary_text = response.choices[0].message.content
            return self._parse_llm_summary(summary_text, meeting_info, 'openai')
            
        except Exception as e:
            logger.error(f"OpenAIè¦ç´„ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_mock_summary(meeting_info)
    
    def _create_summary_prompt(self, meeting_info: Dict[str, Any]) -> str:
        """è¦ç´„ç”Ÿæˆç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        prompt = f"""
ä»¥ä¸‹ã®å›½ä¼š{meeting_info['committee']}ä¼šè­°ï¼ˆ{meeting_info['date']}ï¼‰ã®è­°äº‹éŒ²ã‚’è¦ç´„ã—ã¦ãã ã•ã„ã€‚

ä¼šè­°æƒ…å ±:
- æ—¥ä»˜: {meeting_info['date']}
- å§”å“¡ä¼š: {meeting_info['committee']}
- é™¢: {meeting_info['house']}
- ç™ºè¨€è€…æ•°: {len(meeting_info['speakers'])}å
- å‚åŠ æ”¿å…š: {', '.join(meeting_info['parties'])}

è­°äº‹éŒ²å†…å®¹:
{meeting_info['full_text'][:6000]}

ä»¥ä¸‹ã®å½¢å¼ã§è¦ç´„ã‚’ä½œæˆã—ã¦ãã ã•ã„:

ã€ä¼šè­°æ¦‚è¦ã€‘
(2-3è¡Œã§ä¼šè­°ã®å…¨ä½“çš„ãªå†…å®¹ã‚’èª¬æ˜)

ã€ä¸»è¦è­°è«–ãƒã‚¤ãƒ³ãƒˆã€‘
1. (ç¬¬1ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ)
2. (ç¬¬2ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ)
3. (ç¬¬3ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ)

ã€çµè«–ãƒ»æ±ºè­°äº‹é …ã€‘
(ä¼šè­°ã®çµè«–ã‚„æ±ºå®šäº‹é …ãŒã‚ã‚Œã°è¨˜è¼‰ã€ãªã‘ã‚Œã°ä¸»è¦ãªåˆæ„ç‚¹)

ç°¡æ½”ã§åˆ†ã‹ã‚Šã‚„ã™ã„æ—¥æœ¬èªã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚
        """
        return prompt.strip()
    
    def _parse_llm_summary(self, summary_text: str, meeting_info: Dict[str, Any], model_type: str) -> Dict[str, Any]:
        """LLMç”Ÿæˆã®è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹é€ åŒ–"""
        # ç°¡å˜ãªæ§‹é€ åŒ–ï¼ˆå®Ÿéš›ã¯ã‚ˆã‚Šé«˜åº¦ãªãƒ‘ãƒ¼ã‚¹ãŒå¿…è¦ï¼‰
        sections = summary_text.split('ã€')
        
        overview = ""
        key_points = []
        conclusion = ""
        
        for section in sections:
            if 'ä¼šè­°æ¦‚è¦ã€‘' in section:
                overview = section.split('ã€‘')[1].strip()
            elif 'ä¸»è¦è­°è«–ãƒã‚¤ãƒ³ãƒˆã€‘' in section:
                points_text = section.split('ã€‘')[1].strip()
                key_points = [p.strip() for p in points_text.split('\n') if p.strip() and ('1.' in p or '2.' in p or '3.' in p)]
            elif 'çµè«–' in section or 'æ±ºè­°äº‹é …ã€‘' in section:
                conclusion = section.split('ã€‘')[1].strip()
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if not overview:
            overview = summary_text[:200] + "..."
        if not key_points:
            key_points = ["è©³ç´°ãªè­°è«–ãŒè¡Œã‚ã‚Œã¾ã—ãŸã€‚", "å„å…šã‹ã‚‰æ§˜ã€…ãªæ„è¦‹ãŒæç¤ºã•ã‚Œã¾ã—ãŸã€‚"]
        if not conclusion:
            conclusion = "ä¼šè­°ã¯äºˆå®šé€šã‚Šçµ‚äº†ã—ã¾ã—ãŸã€‚"
        
        summary = {
            'title': f"{meeting_info['date']} {meeting_info['committee']}ä¼šè­°è¦ç´„",
            'overview': overview,
            'key_points': key_points,
            'conclusion': conclusion,
            'participants': {
                'speakers': meeting_info['speakers'],
                'parties': meeting_info['parties']
            },
            'metadata': {
                'summary_type': 'llm_generated',
                'model': f"{model_type}_{self.model_name}",
                'generated_at': datetime.now().isoformat(),
                'original_speech_count': meeting_info['speech_count']
            }
        }
        
        return summary
    
    def save_summaries(self, summaries: List[Dict[str, Any]]):
        """ç”Ÿæˆã•ã‚ŒãŸè¦ç´„ã‚’ä¿å­˜"""
        if not summaries:
            logger.warning("ä¿å­˜ã™ã‚‹è¦ç´„ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åç”Ÿæˆ
        current_date = datetime.now()
        timestamp = current_date.strftime('%Y%m%d_%H%M%S')
        filename = f"meeting_summaries_{timestamp}.json"
        filepath = self.summaries_dir / filename
        
        # è¦ç´„ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜
        summary_data = {
            "metadata": {
                "generated_at": current_date.isoformat(),
                "total_summaries": len(summaries),
                "llm_type": self.llm_type,
                "model": self.model_name,
                "version": "1.0"
            },
            "summaries": summaries
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)
        
        file_size = filepath.stat().st_size / (1024 * 1024)
        logger.info(f"è¦ç´„ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†:")
        logger.info(f"  - ãƒ•ã‚¡ã‚¤ãƒ«: {filepath}")
        logger.info(f"  - ã‚µã‚¤ã‚º: {file_size:.1f} MB")
        logger.info(f"  - è¦ç´„æ•°: {len(summaries)}ä»¶")
        
        # çµ±è¨ˆè¡¨ç¤º
        self.display_summary_stats(summaries)
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
        self.update_summaries_index()
    
    def display_summary_stats(self, summaries: List[Dict[str, Any]]):
        """è¦ç´„çµ±è¨ˆã‚’è¡¨ç¤º"""
        logger.info("\nğŸ“Š ä¼šè­°è¦ç´„ç”Ÿæˆçµ±è¨ˆ:")
        
        # å§”å“¡ä¼šåˆ¥é›†è¨ˆ
        committee_counts = defaultdict(int)
        for summary in summaries:
            title = summary.get('title', '')
            # ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰å§”å“¡ä¼šåã‚’æŠ½å‡º
            for committee in ['æœ¬ä¼šè­°', 'äºˆç®—å§”å“¡ä¼š', 'å¤–å‹™å§”å“¡ä¼š', 'æ–‡æ•™ç§‘å­¦å§”å“¡ä¼š', 'åšç”ŸåŠ´åƒå§”å“¡ä¼š']:
                if committee in title:
                    committee_counts[committee] += 1
                    break
            else:
                committee_counts['ãã®ä»–'] += 1
        
        logger.info("å§”å“¡ä¼šåˆ¥è¦ç´„æ•°:")
        for committee, count in committee_counts.items():
            logger.info(f"  {committee}: {count}ä»¶")
        
        # å¹³å‡çµ±è¨ˆ
        total_speakers = sum(len(s.get('participants', {}).get('speakers', [])) for s in summaries)
        avg_speakers = total_speakers / len(summaries) if summaries else 0
        
        logger.info(f"\nå¹³å‡ç™ºè¨€è€…æ•°: {avg_speakers:.1f}å/ä¼šè­°")
        logger.info(f"ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {self.model_name}")
    
    def update_summaries_index(self):
        """è¦ç´„ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ›´æ–°"""
        try:
            # summariesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
            summary_files = []
            if self.summaries_dir.exists():
                for file_path in self.summaries_dir.glob("summary_*.json"):
                    summary_files.append(file_path.name)
            
            # æ—¥ä»˜é †ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
            summary_files.sort(key=lambda x: x, reverse=True)
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            index_data = {
                "metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "total_files": len(summary_files),
                    "description": "Summary files index for dynamic loading"
                },
                "files": summary_files
            }
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            index_path = self.summaries_dir / "summaries_index.json"
            with open(index_path, 'w', encoding='utf-8') as f:
                json.dump(index_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"ğŸ“ è¦ç´„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°å®Œäº†: {len(summary_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
            logger.info(f"  - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«: {index_path}")
            
        except Exception as e:
            logger.error(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    logger.info("ğŸš€ ä¼šè­°è¦ç´„ç”Ÿæˆé–‹å§‹ (Issue #21)")
    
    generator = MeetingSummaryGenerator()
    
    try:
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰: ç’°å¢ƒå¤‰æ•°ã§åˆ¶é™æ•°ã‚’æŒ‡å®šå¯èƒ½
        test_limit = os.getenv('TEST_LIMIT')
        speech_limit = int(test_limit) if test_limit else None
        
        # è­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        speeches = generator.load_speech_data(limit=speech_limit)
        
        if not speeches:
            logger.error("è­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # ä¼šè­°åˆ¥ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        meetings = generator.group_speeches_by_meeting(speeches)
        
        if not meetings:
            logger.error("è¦ç´„å¯¾è±¡ã®ä¼šè­°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return
        
        # è¦ç´„ç”Ÿæˆ
        logger.info(f"è¦ç´„ç”Ÿæˆé–‹å§‹: {len(meetings)}ä»¶ã®ä¼šè­°")
        summaries = []
        
        for meeting_key, meeting_speeches in list(meetings.items())[:5]:  # æœ€åˆã®5ä¼šè­°ã‚’ãƒ†ã‚¹ãƒˆ
            logger.info(f"è¦ç´„ç”Ÿæˆä¸­: {meeting_key}")
            
            meeting_info = generator.prepare_meeting_text(meeting_speeches)
            summary = generator.generate_summary_with_llm(meeting_info)
            summaries.append(summary)
        
        # è¦ç´„ä¿å­˜
        generator.save_summaries(summaries)
        
        logger.info("âœ¨ ä¼šè­°è¦ç´„ç”Ÿæˆå‡¦ç†å®Œäº† (Issue #21)")
        
    except Exception as e:
        logger.error(f"ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise

if __name__ == "__main__":
    main()