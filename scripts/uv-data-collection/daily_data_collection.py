#!/usr/bin/env python3
"""
æ¯æ—¥å®Ÿè¡Œã•ã‚Œã‚‹éå»2ãƒ¶æœˆåˆ†ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

GitHub Actionsç”¨ã«è¨­è¨ˆï¼š
- éå»2ãƒ¶æœˆåˆ†ã®è­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿ã‚’æ¯æ—¥åé›†
- IPå½è£…ã¨ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
- æ–°ãƒ•ã‚¡ã‚¤ãƒ«åå½¢å¼: speeches_YYYYMMDD_DD.json
- ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ data/raw/speeches/ ã«ä¿å­˜
"""

import os
import json
import time
import random
import requests
import calendar
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
from fake_useragent import UserAgent
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DailyKokkaiAPIClient:
    """æ¯æ—¥å®Ÿè¡Œç”¨ã®å›½ä¼šAPIåé›†ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.base_url = "https://kokkai.ndl.go.jp/api/speech"
        self.session = requests.Session()
        self.ua = UserAgent()
        self.request_count = 0
        self.update_headers()
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        self.project_root = Path(__file__).parent.parent.parent
        self.raw_data_dir = self.project_root / "data" / "raw" / "speeches"
        self.raw_data_dir.mkdir(parents=True, exist_ok=True)
        
    def update_headers(self):
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›´æ–°"""
        referrers = [
            'https://www.google.com/',
            'https://www.yahoo.co.jp/',
            'https://www.bing.com/',
            'https://kokkai.ndl.go.jp/',
            'https://www.ndl.go.jp/'
        ]
        
        headers = {
            'User-Agent': self.ua.random,
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': random.choice(referrers),
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }
        self.session.headers.update(headers)
        
    def rate_limit(self):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™: ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ã‚’èª¿æ•´"""
        self.request_count += 1
        
        # 10ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã«ãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°
        if self.request_count % 10 == 0:
            self.update_headers()
            logger.info(f"ãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–° ({self.request_count}ãƒªã‚¯ã‚¨ã‚¹ãƒˆ)")
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™: 1-3ç§’ã®ãƒ©ãƒ³ãƒ€ãƒ å¾…æ©Ÿ
        wait_time = random.uniform(1.0, 3.0)
        time.sleep(wait_time)
        
    def get_last_day_of_month(self, year: int, month: int) -> int:
        """æŒ‡å®šå¹´æœˆã®æœ€çµ‚æ—¥ã‚’å–å¾—ï¼ˆã†ã‚‹ã†å¹´å¯¾å¿œï¼‰"""
        return calendar.monthrange(year, month)[1]
        
    def get_monthly_data(self, year: int, month: int) -> List[Dict[str, Any]]:
        """æŒ‡å®šæœˆã®è­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        logger.info(f"ğŸ“… {year}å¹´{month}æœˆã®ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")
        
        all_speeches = []
        start_record = 1
        records_per_request = 100
        
        # æŒ‡å®šæœˆã®æœ€å¾Œã®æ—¥ã‚’å–å¾—
        last_day = self.get_last_day_of_month(year, month)
        logger.info(f"ğŸ“… {year}å¹´{month}æœˆ: 1æ—¥ã€œ{last_day}æ—¥ (è¨ˆ{last_day}æ—¥)")
        
        while True:
            self.rate_limit()
            
            params = {
                'startRecord': start_record,
                'maximumRecords': records_per_request,
                'recordPacking': 'json',
                'from': f"{year}-{month:02d}-01",
                'until': f"{year}-{month:02d}-{last_day:02d}"
            }
            
            try:
                logger.info(f"ğŸ” ãƒ¬ã‚³ãƒ¼ãƒ‰ {start_record}ã€œ{start_record + records_per_request - 1} ã‚’å–å¾—ä¸­...")
                response = self.session.get(self.base_url, params=params, timeout=30)
                response.raise_for_status()
                
                data = response.json()
                
                if 'speechRecord' not in data:
                    logger.warning(f"âš ï¸ speechRecord not found in response")
                    break
                    
                speeches = data['speechRecord']
                
                if not speeches:
                    logger.info(f"âœ… {year}å¹´{month}æœˆã®ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
                    break
                    
                # ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
                normalized_speeches = []
                for speech in speeches:
                    normalized_speech = self.normalize_speech_data(speech)
                    if normalized_speech:
                        normalized_speeches.append(normalized_speech)
                
                all_speeches.extend(normalized_speeches)
                logger.info(f"ğŸ“Š {len(normalized_speeches)}ä»¶è¿½åŠ  (ç´¯è¨ˆ: {len(all_speeches)}ä»¶)")
                
                # æ¬¡ã®ãƒšãƒ¼ã‚¸ã¸
                start_record += records_per_request
                
                # å®‰å…¨åˆ¶é™: æœˆé–“5000ä»¶ã¾ã§
                if len(all_speeches) >= 5000:
                    logger.warning(f"âš ï¸ æœˆé–“åˆ¶é™(5000ä»¶)ã«é”ã—ãŸãŸã‚çµ‚äº†")
                    break
                    
            except Exception as e:
                logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
                break
                
        logger.info(f"ğŸ‰ {year}å¹´{month}æœˆ: åˆè¨ˆ {len(all_speeches)}ä»¶ åé›†å®Œäº†")
        return all_speeches
        
    def normalize_speech_data(self, speech: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–"""
        try:
            # åŸºæœ¬çš„ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æŠ½å‡º
            normalized = {
                'id': speech.get('speechID', ''),
                'date': speech.get('date', ''),
                'session': int(speech.get('session', 0)),
                'house': speech.get('nameOfHouse', ''),
                'committee': speech.get('nameOfMeeting', ''),
                'meeting_info': self.extract_meeting_details(speech),
                'speaker': speech.get('speaker', ''),
                'party': None,
                'party_normalized': None,
                'party_aliases': [],
                'position': speech.get('speakerPosition', ''),
                'text': speech.get('speech', ''),
                'url': speech.get('speechURL', ''),
                'created_at': datetime.now().isoformat()
            }
            
            # æ”¿å…šæƒ…å ±ã®å‡¦ç†
            speaker_group = speech.get('speakerGroup', '')
            if speaker_group:
                normalized['party'] = speaker_group
                normalized['party_normalized'] = self.normalize_party_name(speaker_group)
                normalized['party_aliases'] = self.get_party_aliases(normalized['party_normalized'])
            
            return normalized
            
        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return None
            
    def normalize_party_name(self, party_name: str) -> str:
        """æ”¿å…šåã‚’æ­£è¦åŒ–"""
        party_mapping = {
            'è‡ªç”±æ°‘ä¸»å…š': 'è‡ªç”±æ°‘ä¸»å…š',
            'è‡ªæ°‘å…š': 'è‡ªç”±æ°‘ä¸»å…š',
            'ç«‹æ†²æ°‘ä¸»å…š': 'ç«‹æ†²æ°‘ä¸»å…š',
            'ç«‹æ°‘': 'ç«‹æ†²æ°‘ä¸»å…š',
            'æ—¥æœ¬ç¶­æ–°ã®ä¼š': 'æ—¥æœ¬ç¶­æ–°ã®ä¼š',
            'ç¶­æ–°': 'æ—¥æœ¬ç¶­æ–°ã®ä¼š',
            'å…¬æ˜å…š': 'å…¬æ˜å…š',
            'å…¬æ˜': 'å…¬æ˜å…š',
            'æ—¥æœ¬å…±ç”£å…š': 'æ—¥æœ¬å…±ç”£å…š',
            'å…±ç”£å…š': 'æ—¥æœ¬å…±ç”£å…š',
            'å…±ç”£': 'æ—¥æœ¬å…±ç”£å…š',
            'å›½æ°‘æ°‘ä¸»å…š': 'å›½æ°‘æ°‘ä¸»å…š',
            'å›½æ°‘': 'å›½æ°‘æ°‘ä¸»å…š',
            'ã‚Œã„ã‚æ–°é¸çµ„': 'ã‚Œã„ã‚æ–°é¸çµ„',
            'ã‚Œã„ã‚': 'ã‚Œã„ã‚æ–°é¸çµ„'
        }
        
        for key, normalized in party_mapping.items():
            if key in party_name:
                return normalized
        
        return party_name
        
    def get_party_aliases(self, party_name: str) -> List[str]:
        """æ”¿å…šã®ç•¥ç§°ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        aliases_mapping = {
            'è‡ªç”±æ°‘ä¸»å…š': ['è‡ªæ°‘å…š', 'è‡ªæ°‘', 'LDP'],
            'ç«‹æ†²æ°‘ä¸»å…š': ['ç«‹æ°‘', 'ç«‹æ†²'],
            'æ—¥æœ¬ç¶­æ–°ã®ä¼š': ['ç¶­æ–°', 'ç¶­æ–°ã®ä¼š', 'å¤§é˜ªç¶­æ–°'],
            'å…¬æ˜å…š': ['å…¬æ˜'],
            'æ—¥æœ¬å…±ç”£å…š': ['å…±ç”£å…š', 'å…±ç”£', 'JCP'],
            'å›½æ°‘æ°‘ä¸»å…š': ['å›½æ°‘'],
            'ã‚Œã„ã‚æ–°é¸çµ„': ['ã‚Œã„ã‚']
        }
        
        return aliases_mapping.get(party_name, [])
        
    def extract_meeting_details(self, speech: Dict[str, Any]) -> Dict[str, Any]:
        """ä¼šè­°ã®è©³ç´°æƒ…å ±ã‚’æŠ½å‡º"""
        try:
            meeting_details = {
                'session_name': speech.get('nameOfSession', ''),
                'meeting_name': speech.get('nameOfMeeting', ''),
                'house': speech.get('nameOfHouse', ''),
                'meeting_number': speech.get('meetingNumber', ''),
                'date': speech.get('date', ''),
                'issue': speech.get('issue', ''),
                'pdf_url': speech.get('pdfURL', ''),
                'speech_order': speech.get('speechOrder', ''),
                'meeting_type': self.classify_meeting_type(speech.get('nameOfMeeting', ''))
            }
            
            return meeting_details
            
        except Exception as e:
            logger.error(f"âŒ ä¼šè­°è©³ç´°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return {}
            
    def classify_meeting_type(self, meeting_name: str) -> str:
        """ä¼šè­°åã‹ã‚‰ä¼šè­°ç¨®åˆ¥ã‚’åˆ†é¡"""
        if not meeting_name:
            return 'ä¸æ˜'
            
        if 'æœ¬ä¼šè­°' in meeting_name:
            return 'æœ¬ä¼šè­°'
        elif 'äºˆç®—å§”å“¡ä¼š' in meeting_name:
            return 'äºˆç®—å§”å“¡ä¼š'
        elif 'ç‰¹åˆ¥å§”å“¡ä¼š' in meeting_name:
            return 'ç‰¹åˆ¥å§”å“¡ä¼š'
        elif 'å¸¸ä»»å§”å“¡ä¼š' in meeting_name or 'å§”å“¡ä¼š' in meeting_name:
            return 'å¸¸ä»»å§”å“¡ä¼š'
        elif 'å¯©æŸ»ä¼š' in meeting_name:
            return 'å¯©æŸ»ä¼š'
        elif 'èª¿æŸ»ä¼š' in meeting_name:
            return 'èª¿æŸ»ä¼š'
        elif 'åˆ†ç§‘ä¼š' in meeting_name:
            return 'åˆ†ç§‘ä¼š'
        else:
            return 'ãã®ä»–'
        
    def generate_filename(self, year: int, month: int, day_range: str) -> str:
        """æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åå½¢å¼ã§ç”Ÿæˆ: speeches_YYYYMMDD_DD.json"""
        return f"speeches_{year}{month:02d}01_{day_range}.json"
        
    def save_monthly_data(self, speeches: List[Dict[str, Any]], year: int, month: int):
        """æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        if not speeches:
            logger.warning(f"âš ï¸ {year}å¹´{month}æœˆ: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            return
            
        # æ—¥ä»˜ç¯„å›²ã®è¨ˆç®—
        dates = [s['date'] for s in speeches if s['date']]
        if dates:
            dates.sort()
            first_day = dates[0].split('-')[2]
            last_day = dates[-1].split('-')[2]
            day_range = f"{first_day}_{last_day}" if first_day != last_day else first_day
        else:
            # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯æœˆã®æœ€çµ‚æ—¥ã‚’ä½¿ç”¨
            last_day_of_month = self.get_last_day_of_month(year, month)
            day_range = f"{last_day_of_month:02d}"
            
        filename = self.generate_filename(year, month, day_range)
        filepath = self.raw_data_dir / filename
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã§ä¿å­˜
        data = {
            "metadata": {
                "data_type": "speeches_raw",
                "year": year,
                "month": month,
                "total_count": len(speeches),
                "generated_at": datetime.now().isoformat(),
                "source": "https://kokkai.ndl.go.jp/api.html",
                "collection_method": "daily_automated_collection",
                "filename_format": "speeches_YYYYMMDD_DD.json"
            },
            "data": speeches
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        file_size = filepath.stat().st_size / (1024 * 1024)
        logger.info(f"ğŸ’¾ ä¿å­˜å®Œäº†: {filename} ({file_size:.1f} MB)")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logger.info("ğŸš€ æ¯æ—¥ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šå–å¾—
    months_back = float(os.getenv('MONTHS_BACK', '2'))
    force_update = os.getenv('FORCE_UPDATE', 'false').lower() == 'true'
    
    logger.info(f"ğŸ“‹ è¨­å®š: éå»{months_back}ãƒ¶æœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†")
    logger.info(f"ğŸ“‹ å¼·åˆ¶æ›´æ–°: {force_update}")
    
    client = DailyKokkaiAPIClient()
    
    # å°æ•°ç‚¹æœˆæ•°ã‚’é©åˆ‡ã«å‡¦ç†
    current_date = datetime.now()
    target_months = []
    
    if months_back < 1:
        # 1ãƒ¶æœˆæœªæº€ã®å ´åˆã¯ç¾åœ¨ã®æœˆã®ã¿
        target_months.append((current_date.year, current_date.month))
        logger.info(f"ğŸ“… å°æ•°ç‚¹æœˆæ•°({months_back})ã®ãŸã‚ç¾åœ¨æœˆã®ã¿åé›†: {current_date.year}å¹´{current_date.month}æœˆ")
    else:
        # 1ãƒ¶æœˆä»¥ä¸Šã®å ´åˆã¯æ•´æ•°éƒ¨åˆ†ã®æœˆæ•°åˆ†ã‚’åé›†
        months_to_collect = int(months_back) + (1 if months_back % 1 > 0 else 0)
        logger.info(f"ğŸ“… å°æ•°ç‚¹æœˆæ•°({months_back})ã‹ã‚‰{months_to_collect}ãƒ¶æœˆåˆ†ã‚’åé›†å¯¾è±¡ã¨ã—ã¾ã™")
        
        for i in range(months_to_collect):
            target_date = current_date - relativedelta(months=i)
            target_months.append((target_date.year, target_date.month))
    
    # åé›†å¯¾è±¡æœˆã‚’è¡¨ç¤º
    logger.info(f"ğŸ“… åé›†å¯¾è±¡æœˆ: {', '.join([f'{y}å¹´{m}æœˆ' for y, m in target_months])}")
    
    # å„æœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    for year, month in target_months:
        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
        existing_files = list(client.raw_data_dir.glob(f"speeches_{year}{month:02d}*.json"))
        
        if existing_files and not force_update:
            logger.info(f"â­ï¸ {year}å¹´{month}æœˆ: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚ã‚Šã€ã‚¹ã‚­ãƒƒãƒ—")
            continue
            
        # ãƒ‡ãƒ¼ã‚¿åé›†
        speeches = client.get_monthly_data(year, month)
        
        if speeches:
            client.save_monthly_data(speeches, year, month)
        else:
            logger.warning(f"âš ï¸ {year}å¹´{month}æœˆ: ãƒ‡ãƒ¼ã‚¿ãªã—")
            
    logger.info("âœ¨ æ¯æ—¥ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†!")

if __name__ == "__main__":
    main()