#!/usr/bin/env python3
"""
é€²è¡Œçš„ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

GitHub Actionsç”¨ã«è¨­è¨ˆã•ã‚ŒãŸé€²è¡Œçš„ãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ ï¼š
- æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤æ—¥ä»˜ã‚’åŸºæº–ã¨ã—ãŸé€²è¡Œçš„ãªéå»ãƒ‡ãƒ¼ã‚¿åé›†
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: æœ€å¤ãƒ‡ãƒ¼ã‚¿ã‚ˆã‚Š3ãƒ¶æœˆå‰ã¾ã§é¡ã£ã¦åé›†
- åˆå›å®Ÿè¡Œæ™‚ã¯ç¾åœ¨ã‹ã‚‰éå»3ãƒ¶æœˆåˆ†ã‚’åé›†
- IPå½è£…ã¨ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
- ãƒ•ã‚¡ã‚¤ãƒ«åå½¢å¼: speeches_YYYYMMDD_DD.json
- ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’ data/raw/speeches/ ã«ä¿å­˜

ç’°å¢ƒå¤‰æ•°:
- MONTHS_BACK: åé›†æœˆæ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 3)
- USE_PROGRESSIVE: é€²è¡Œçš„åé›†ã‚’ä½¿ç”¨ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: true)  
- FORCE_UPDATE: å¼·åˆ¶æ›´æ–° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: false)
"""

import os
import json
import time
import random
import requests
import calendar
from datetime import datetime, timedelta
from dateutil.relativedelta import relativedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
from fake_useragent import UserAgent
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DailyKokkaiAPIClient:
    """æ¯æ—¥å®Ÿè¡Œç”¨ã®å›½ä¼šAPIåé›†ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self):
        self.base_url = "https://kokkai.ndl.go.jp/api/speech"
        self.session = requests.Session()
        self.ua = UserAgent()
        self.request_count = 0
        self.update_headers()
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        self.project_root = Path(__file__).parent.parent.parent
        self.raw_data_dir = self.project_root / "data" / "raw" / "speeches"
        self.raw_data_dir.mkdir(parents=True, exist_ok=True)
        
    def update_headers(self):
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ˜ãƒƒãƒ€ãƒ¼ã‚’æ›´æ–°"""
        referrers = [
            'https://www.google.com/',
            'https://www.yahoo.co.jp/',
            'https://www.bing.com/',
            'https://kokkai.ndl.go.jp/',
            'https://www.ndl.go.jp/'
        ]
        
        headers = {
            'User-Agent': self.ua.random,
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'ja,en-US;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Referer': random.choice(referrers),
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }
        self.session.headers.update(headers)
        
    def rate_limit(self):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™: ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ã‚’èª¿æ•´"""
        self.request_count += 1
        
        # 10ãƒªã‚¯ã‚¨ã‚¹ãƒˆã”ã¨ã«ãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–°
        if self.request_count % 10 == 0:
            self.update_headers()
            logger.info(f"ãƒ˜ãƒƒãƒ€ãƒ¼æ›´æ–° ({self.request_count}ãƒªã‚¯ã‚¨ã‚¹ãƒˆ)")
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™: 1-3ç§’ã®ãƒ©ãƒ³ãƒ€ãƒ å¾…æ©Ÿ
        wait_time = random.uniform(1.0, 3.0)
        time.sleep(wait_time)
        
    def get_last_day_of_month(self, year: int, month: int) -> int:
        """æŒ‡å®šå¹´æœˆã®æœ€çµ‚æ—¥ã‚’å–å¾—ï¼ˆã†ã‚‹ã†å¹´å¯¾å¿œï¼‰"""
        return calendar.monthrange(year, month)[1]
        
    def get_monthly_data(self, year: int, month: int) -> List[Dict[str, Any]]:
        """æŒ‡å®šæœˆã®è­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        logger.info(f"ğŸ“… {year}å¹´{month}æœˆã®ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")
        
        all_speeches = []
        start_record = 1
        records_per_request = 100
        
        # æŒ‡å®šæœˆã®æœ€å¾Œã®æ—¥ã‚’å–å¾—
        last_day = self.get_last_day_of_month(year, month)
        logger.info(f"ğŸ“… {year}å¹´{month}æœˆ: 1æ—¥ã€œ{last_day}æ—¥ (è¨ˆ{last_day}æ—¥)")
        
        while True:
            self.rate_limit()
            
            params = {
                'startRecord': start_record,
                'maximumRecords': records_per_request,
                'recordPacking': 'json',
                'from': f"{year}-{month:02d}-01",
                'until': f"{year}-{month:02d}-{last_day:02d}"
            }
            
            try:
                logger.info(f"ğŸ” ãƒ¬ã‚³ãƒ¼ãƒ‰ {start_record}ã€œ{start_record + records_per_request - 1} ã‚’å–å¾—ä¸­...")
                response = self.session.get(self.base_url, params=params, timeout=30)
                response.raise_for_status()
                
                data = response.json()
                
                if 'speechRecord' not in data:
                    logger.warning(f"âš ï¸ speechRecord not found in response")
                    break
                    
                speeches = data['speechRecord']
                
                if not speeches:
                    logger.info(f"âœ… {year}å¹´{month}æœˆã®ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†")
                    break
                    
                # ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–
                normalized_speeches = []
                for speech in speeches:
                    normalized_speech = self.normalize_speech_data(speech)
                    if normalized_speech:
                        normalized_speeches.append(normalized_speech)
                
                all_speeches.extend(normalized_speeches)
                logger.info(f"ğŸ“Š {len(normalized_speeches)}ä»¶è¿½åŠ  (ç´¯è¨ˆ: {len(all_speeches)}ä»¶)")
                
                # æ¬¡ã®ãƒšãƒ¼ã‚¸ã¸
                start_record += records_per_request
                
                # å®‰å…¨åˆ¶é™: æœˆé–“5000ä»¶ã¾ã§
                if len(all_speeches) >= 5000:
                    logger.warning(f"âš ï¸ æœˆé–“åˆ¶é™(5000ä»¶)ã«é”ã—ãŸãŸã‚çµ‚äº†")
                    break
                    
            except Exception as e:
                logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
                break
                
        logger.info(f"ğŸ‰ {year}å¹´{month}æœˆ: åˆè¨ˆ {len(all_speeches)}ä»¶ åé›†å®Œäº†")
        return all_speeches
        
    def normalize_speech_data(self, speech: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """è­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿ã‚’æ­£è¦åŒ–"""
        try:
            # åŸºæœ¬çš„ãªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æŠ½å‡º
            normalized = {
                'id': speech.get('speechID', ''),
                'date': speech.get('date', ''),
                'session': int(speech.get('session', 0)),
                'house': speech.get('nameOfHouse', ''),
                'committee': speech.get('nameOfMeeting', ''),
                'meeting_info': self.extract_meeting_details(speech),
                'speaker': speech.get('speaker', ''),
                'party': None,
                'party_normalized': None,
                'party_aliases': [],
                'position': speech.get('speakerPosition', ''),
                'text': speech.get('speech', ''),
                'url': speech.get('speechURL', ''),
                'created_at': datetime.now().isoformat()
            }
            
            # æ”¿å…šæƒ…å ±ã®å‡¦ç†
            speaker_group = speech.get('speakerGroup', '')
            if speaker_group:
                normalized['party'] = speaker_group
                normalized['party_normalized'] = self.normalize_party_name(speaker_group)
                normalized['party_aliases'] = self.get_party_aliases(normalized['party_normalized'])
            
            return normalized
            
        except Exception as e:
            logger.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            return None
            
    def normalize_party_name(self, party_name: str) -> str:
        """æ”¿å…šåã‚’æ­£è¦åŒ–"""
        party_mapping = {
            'è‡ªç”±æ°‘ä¸»å…š': 'è‡ªç”±æ°‘ä¸»å…š',
            'è‡ªæ°‘å…š': 'è‡ªç”±æ°‘ä¸»å…š',
            'ç«‹æ†²æ°‘ä¸»å…š': 'ç«‹æ†²æ°‘ä¸»å…š',
            'ç«‹æ°‘': 'ç«‹æ†²æ°‘ä¸»å…š',
            'æ—¥æœ¬ç¶­æ–°ã®ä¼š': 'æ—¥æœ¬ç¶­æ–°ã®ä¼š',
            'ç¶­æ–°': 'æ—¥æœ¬ç¶­æ–°ã®ä¼š',
            'å…¬æ˜å…š': 'å…¬æ˜å…š',
            'å…¬æ˜': 'å…¬æ˜å…š',
            'æ—¥æœ¬å…±ç”£å…š': 'æ—¥æœ¬å…±ç”£å…š',
            'å…±ç”£å…š': 'æ—¥æœ¬å…±ç”£å…š',
            'å…±ç”£': 'æ—¥æœ¬å…±ç”£å…š',
            'å›½æ°‘æ°‘ä¸»å…š': 'å›½æ°‘æ°‘ä¸»å…š',
            'å›½æ°‘': 'å›½æ°‘æ°‘ä¸»å…š',
            'ã‚Œã„ã‚æ–°é¸çµ„': 'ã‚Œã„ã‚æ–°é¸çµ„',
            'ã‚Œã„ã‚': 'ã‚Œã„ã‚æ–°é¸çµ„'
        }
        
        for key, normalized in party_mapping.items():
            if key in party_name:
                return normalized
        
        return party_name
        
    def get_party_aliases(self, party_name: str) -> List[str]:
        """æ”¿å…šã®ç•¥ç§°ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        aliases_mapping = {
            'è‡ªç”±æ°‘ä¸»å…š': ['è‡ªæ°‘å…š', 'è‡ªæ°‘', 'LDP'],
            'ç«‹æ†²æ°‘ä¸»å…š': ['ç«‹æ°‘', 'ç«‹æ†²'],
            'æ—¥æœ¬ç¶­æ–°ã®ä¼š': ['ç¶­æ–°', 'ç¶­æ–°ã®ä¼š', 'å¤§é˜ªç¶­æ–°'],
            'å…¬æ˜å…š': ['å…¬æ˜'],
            'æ—¥æœ¬å…±ç”£å…š': ['å…±ç”£å…š', 'å…±ç”£', 'JCP'],
            'å›½æ°‘æ°‘ä¸»å…š': ['å›½æ°‘'],
            'ã‚Œã„ã‚æ–°é¸çµ„': ['ã‚Œã„ã‚']
        }
        
        return aliases_mapping.get(party_name, [])
        
    def extract_meeting_details(self, speech: Dict[str, Any]) -> Dict[str, Any]:
        """ä¼šè­°ã®è©³ç´°æƒ…å ±ã‚’æŠ½å‡º"""
        try:
            meeting_details = {
                'session_name': speech.get('nameOfSession', ''),
                'meeting_name': speech.get('nameOfMeeting', ''),
                'house': speech.get('nameOfHouse', ''),
                'meeting_number': speech.get('meetingNumber', ''),
                'date': speech.get('date', ''),
                'issue': speech.get('issue', ''),
                'pdf_url': speech.get('pdfURL', ''),
                'speech_order': speech.get('speechOrder', ''),
                'meeting_type': self.classify_meeting_type(speech.get('nameOfMeeting', ''))
            }
            
            return meeting_details
            
        except Exception as e:
            logger.error(f"âŒ ä¼šè­°è©³ç´°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return {}
            
    def classify_meeting_type(self, meeting_name: str) -> str:
        """ä¼šè­°åã‹ã‚‰ä¼šè­°ç¨®åˆ¥ã‚’åˆ†é¡"""
        if not meeting_name:
            return 'ä¸æ˜'
            
        if 'æœ¬ä¼šè­°' in meeting_name:
            return 'æœ¬ä¼šè­°'
        elif 'äºˆç®—å§”å“¡ä¼š' in meeting_name:
            return 'äºˆç®—å§”å“¡ä¼š'
        elif 'ç‰¹åˆ¥å§”å“¡ä¼š' in meeting_name:
            return 'ç‰¹åˆ¥å§”å“¡ä¼š'
        elif 'å¸¸ä»»å§”å“¡ä¼š' in meeting_name or 'å§”å“¡ä¼š' in meeting_name:
            return 'å¸¸ä»»å§”å“¡ä¼š'
        elif 'å¯©æŸ»ä¼š' in meeting_name:
            return 'å¯©æŸ»ä¼š'
        elif 'èª¿æŸ»ä¼š' in meeting_name:
            return 'èª¿æŸ»ä¼š'
        elif 'åˆ†ç§‘ä¼š' in meeting_name:
            return 'åˆ†ç§‘ä¼š'
        else:
            return 'ãã®ä»–'
        
    def generate_filename(self, year: int, month: int, day_range: str) -> str:
        """æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«åå½¢å¼ã§ç”Ÿæˆ: speeches_YYYYMMDD_DD.json"""
        return f"speeches_{year}{month:02d}01_{day_range}.json"
        
    def save_monthly_data(self, speeches: List[Dict[str, Any]], year: int, month: int):
        """æœˆæ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        if not speeches:
            logger.warning(f"âš ï¸ {year}å¹´{month}æœˆ: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            return
            
        # æ—¥ä»˜ç¯„å›²ã®è¨ˆç®—
        dates = [s['date'] for s in speeches if s['date']]
        if dates:
            dates.sort()
            first_day = dates[0].split('-')[2]
            last_day = dates[-1].split('-')[2]
            day_range = f"{first_day}_{last_day}" if first_day != last_day else first_day
        else:
            # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯æœˆã®æœ€çµ‚æ—¥ã‚’ä½¿ç”¨
            last_day_of_month = self.get_last_day_of_month(year, month)
            day_range = f"{last_day_of_month:02d}"
            
        filename = self.generate_filename(year, month, day_range)
        filepath = self.raw_data_dir / filename
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã§ä¿å­˜
        data = {
            "metadata": {
                "data_type": "speeches_raw",
                "year": year,
                "month": month,
                "total_count": len(speeches),
                "generated_at": datetime.now().isoformat(),
                "source": "https://kokkai.ndl.go.jp/api.html",
                "collection_method": "daily_automated_collection",
                "filename_format": "speeches_YYYYMMDD_DD.json"
            },
            "data": speeches
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
        file_size = filepath.stat().st_size / (1024 * 1024)
        logger.info(f"ğŸ’¾ ä¿å­˜å®Œäº†: {filename} ({file_size:.1f} MB)")

def get_progressive_collection_months(client, months_to_collect=3):
    """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åŸºã«é€²è¡Œçš„ãªåé›†å¯¾è±¡æœˆã‚’æ±ºå®š"""
    
    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€å¤ã®æ—¥ä»˜ã‚’æ¤œç´¢
    oldest_date = None
    
    # ã™ã¹ã¦ã®æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ€å¤ã®æ—¥ä»˜ã‚’æ¢ã™
    existing_files = list(client.raw_data_dir.glob("speeches_*.json"))
    
    if existing_files:
        logger.info(f"ğŸ” æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ« {len(existing_files)} ä»¶ã‹ã‚‰æœ€å¤æ—¥ä»˜ã‚’æ¤œç´¢ä¸­...")
        
        for file_path in existing_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                # ãƒ‡ãƒ¼ã‚¿å†…ã®æ—¥ä»˜ã‚’ãƒã‚§ãƒƒã‚¯
                if 'data' in data:
                    for speech in data['data']:
                        if 'date' in speech and speech['date']:
                            try:
                                speech_date = datetime.fromisoformat(speech['date'].replace('Z', '+00:00'))
                                if oldest_date is None or speech_date < oldest_date:
                                    oldest_date = speech_date
                            except (ValueError, TypeError):
                                continue
                                
            except Exception as e:
                logger.warning(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
                continue
    
    target_months = []
    
    if oldest_date:
        logger.info(f"ğŸ“Š æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤æ—¥ä»˜: {oldest_date.strftime('%Y-%m-%d')}")
        
        # æœ€å¤æ—¥ä»˜ã‚ˆã‚Šã‚‚éå»ã®æœˆã‚’åé›†å¯¾è±¡ã¨ã™ã‚‹
        base_date = oldest_date.replace(day=1) - relativedelta(months=1)
        
        for i in range(months_to_collect):
            target_date = base_date - relativedelta(months=i)
            target_months.append((target_date.year, target_date.month))
            
        logger.info(f"ğŸ“… é€²è¡Œçš„åé›†: æœ€å¤æ—¥ä»˜ {oldest_date.strftime('%Y-%m')} ã‚ˆã‚Šéå» {months_to_collect} ãƒ¶æœˆåˆ†")
        
    else:
        logger.info("ğŸ“Š æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãªã—: ç¾åœ¨æ—¥ä»˜ã‹ã‚‰éå»ãƒ‡ãƒ¼ã‚¿ã‚’åé›†")
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯ç¾åœ¨ã‹ã‚‰éå»ã¸
        current_date = datetime.now()
        for i in range(months_to_collect):
            target_date = current_date - relativedelta(months=i)
            target_months.append((target_date.year, target_date.month))
            
        logger.info(f"ğŸ“… åˆå›åé›†: ç¾åœ¨ã‹ã‚‰éå» {months_to_collect} ãƒ¶æœˆåˆ†")
    
    return target_months

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    logger.info("ğŸš€ æ¯æ—¥ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹...")
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šå–å¾—
    months_back = float(os.getenv('MONTHS_BACK', '3'))  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’3ãƒ¶æœˆã«å¤‰æ›´
    force_update = os.getenv('FORCE_UPDATE', 'false').lower() == 'true'
    use_progressive = os.getenv('USE_PROGRESSIVE', 'true').lower() == 'true'
    
    logger.info(f"ğŸ“‹ è¨­å®š: {months_back}ãƒ¶æœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†")
    logger.info(f"ğŸ“‹ å¼·åˆ¶æ›´æ–°: {force_update}")
    logger.info(f"ğŸ“‹ é€²è¡Œçš„åé›†: {use_progressive}")
    
    client = DailyKokkaiAPIClient()
    
    if use_progressive:
        # æ–°ã—ã„é€²è¡Œçš„åé›†ãƒ­ã‚¸ãƒƒã‚¯
        target_months = get_progressive_collection_months(client, int(months_back))
    else:
        # å¾“æ¥ã®ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ä¿æŒï¼‰
        current_date = datetime.now()
        target_months = []
        
        if months_back < 1:
            target_months.append((current_date.year, current_date.month))
            logger.info(f"ğŸ“… å°æ•°ç‚¹æœˆæ•°({months_back})ã®ãŸã‚ç¾åœ¨æœˆã®ã¿åé›†")
        else:
            months_to_collect = int(months_back) + (1 if months_back % 1 > 0 else 0)
            logger.info(f"ğŸ“… å¾“æ¥ãƒ­ã‚¸ãƒƒã‚¯: {months_to_collect}ãƒ¶æœˆåˆ†ã‚’åé›†å¯¾è±¡")
            
            for i in range(months_to_collect):
                target_date = current_date - relativedelta(months=i)
                target_months.append((target_date.year, target_date.month))
    
    # åé›†å¯¾è±¡æœˆã‚’è¡¨ç¤º
    logger.info(f"ğŸ“… åé›†å¯¾è±¡æœˆ: {', '.join([f'{y}å¹´{m}æœˆ' for y, m in target_months])}")
    
    # å„æœˆã®ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    for year, month in target_months:
        # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
        existing_files = list(client.raw_data_dir.glob(f"speeches_{year}{month:02d}*.json"))
        
        if existing_files and not force_update:
            logger.info(f"â­ï¸ {year}å¹´{month}æœˆ: æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚ã‚Šã€ã‚¹ã‚­ãƒƒãƒ—")
            continue
            
        # ãƒ‡ãƒ¼ã‚¿åé›†
        speeches = client.get_monthly_data(year, month)
        
        if speeches:
            client.save_monthly_data(speeches, year, month)
        else:
            logger.warning(f"âš ï¸ {year}å¹´{month}æœˆ: ãƒ‡ãƒ¼ã‚¿ãªã—")
            
    logger.info("âœ¨ æ¯æ—¥ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†!")

if __name__ == "__main__":
    main()