#!/usr/bin/env python3
"""
æœ€çµ‚é‡è¤‡é™¤å»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
åŒä¸€äººç‰©ã®é‡è¤‡ã‚’å‰Šé™¤ã—ã€æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
"""

import json
import logging
from datetime import datetime
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def fix_duplicates_final():
    """æœ€çµ‚çš„ãªé‡è¤‡é™¤å»"""
    logger.info("ğŸ”§ æœ€çµ‚é‡è¤‡é™¤å»é–‹å§‹...")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data_dir = Path(__file__).parent.parent.parent / "frontend" / "public" / "data" / "sangiin_candidates"
    input_file = data_dir / "go2senkyo_optimized_latest.json"
    
    with open(input_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    original_count = len(data['data'])
    logger.info(f"ğŸ“Š å…ƒãƒ‡ãƒ¼ã‚¿: {original_count}å")
    
    # é‡è¤‡æ¤œå‡ºã¨é™¤å»
    seen_urls = set()
    seen_names = set()
    unique_candidates = []
    removed_duplicates = []
    
    for candidate in data['data']:
        name = candidate.get('name', '')
        prefecture = candidate.get('prefecture', '')
        profile_url = candidate.get('profile_url', '')
        
        is_duplicate = False
        
        # 1. URLãƒ™ãƒ¼ã‚¹ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆæœ€å„ªå…ˆï¼‰
        if profile_url and profile_url in seen_urls:
            is_duplicate = True
            reason = f"åŒä¸€URL ({profile_url})"
        
        # 2. åŒåå€™è£œè€…ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
        elif name in seen_names:
            is_duplicate = True
            reason = f"åŒåå€™è£œè€…"
        
        if is_duplicate:
            removed_duplicates.append(candidate)
            logger.info(f"ğŸ—‘ï¸ é‡è¤‡é™¤å»: {name} ({prefecture}) - {reason}")
        else:
            unique_candidates.append(candidate)
            if profile_url:
                seen_urls.add(profile_url)
            seen_names.add(name)
    
    # çµ±è¨ˆå†è¨ˆç®—
    party_stats = {}
    prefecture_stats = {}
    
    for candidate in unique_candidates:
        party = candidate.get('party', 'æœªåˆ†é¡')
        prefecture = candidate.get('prefecture', 'æœªåˆ†é¡')
        
        party_stats[party] = party_stats.get(party, 0) + 1
        prefecture_stats[prefecture] = prefecture_stats.get(prefecture, 0) + 1
    
    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
    fixed_data = {
        "metadata": {
            "data_type": "go2senkyo_complete_structured_sangiin_2025_fixed",
            "collection_method": "structured_html_extraction_all_47_prefectures_deduplicated",
            "total_candidates": len(unique_candidates),
            "candidates_with_kana": len([c for c in unique_candidates if c.get('name_kana')]),
            "successful_prefectures": 47,
            "failed_prefectures": 0,
            "duplicates_removed": len(removed_duplicates),
            "generated_at": datetime.now().isoformat(),
            "source_site": "sangiin.go2senkyo.com",
            "coverage": {
                "constituency_types": 1,
                "parties": len(party_stats),
                "prefectures": len(prefecture_stats)
            }
        },
        "statistics": {
            "by_party": party_stats,
            "by_prefecture": prefecture_stats,
            "by_constituency_type": {"single_member": len(unique_candidates)}
        },
        "data": unique_candidates
    }
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = data_dir / f"go2senkyo_complete_fixed_{timestamp}.json"
    latest_file = data_dir / "go2senkyo_optimized_latest.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(fixed_data, f, ensure_ascii=False, indent=2)
    
    with open(latest_file, 'w', encoding='utf-8') as f:
        json.dump(fixed_data, f, ensure_ascii=False, indent=2)
    
    logger.info(f"ğŸ“ å›ºå®šãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {output_file}")
    logger.info(f"ğŸ“ æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°: {latest_file}")
    
    # çµæœå ±å‘Š
    logger.info(f"\nâœ… é‡è¤‡é™¤å»å®Œäº†:")
    logger.info(f"  å…ƒãƒ‡ãƒ¼ã‚¿: {original_count}å")
    logger.info(f"  é™¤å»æ•°: {len(removed_duplicates)}å")
    logger.info(f"  æœ€çµ‚ãƒ‡ãƒ¼ã‚¿: {len(unique_candidates)}å")
    logger.info(f"  æ”¿å…šæ•°: {len(party_stats)}æ”¿å…š")
    logger.info(f"  éƒ½é“åºœçœŒæ•°: {len(prefecture_stats)}éƒ½é“åºœçœŒ")
    
    if removed_duplicates:
        logger.info(f"\nğŸ—‘ï¸ é™¤å»ã•ã‚ŒãŸé‡è¤‡:")
        for candidate in removed_duplicates:
            logger.info(f"  - {candidate['name']} ({candidate.get('prefecture', 'ä¸æ˜')})")
    
    return output_file

if __name__ == "__main__":
    fix_duplicates_final()