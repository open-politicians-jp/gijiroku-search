#!/usr/bin/env python3
"""
å‚è­°é™¢è­°å“¡CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›ã—ã€é©åˆ‡ãªã‚µã‚¤ã‚ºã«åˆ†å‰²ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹:
- SmartNews Media Research Institute (SMRI) - House of Councillors Database
- URL: https://smartnews-smri.github.io/house-of-councillors/
- ãƒ©ã‚¤ã‚»ãƒ³ã‚¹: å…ƒã‚½ãƒ¼ã‚¹ã®ãƒ©ã‚¤ã‚»ãƒ³ã‚¹æ¡é …ã«å¾“ã†

æ©Ÿèƒ½:
- CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨æ­£è¦åŒ–
- æ”¿å…šåã®æ­£è¦åŒ–
- ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã«åŸºã¥ã„ãŸåˆ†å‰² (ç´„50-60å/ãƒ•ã‚¡ã‚¤ãƒ«)
- frontend/public/data/legislators/ ã«ä¿å­˜
"""

import csv
import json
import re
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

class SangiinCSVConverter:
    """å‚è­°é™¢è­°å“¡CSVâ†’JSONå¤‰æ›ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent.parent
        self.csv_file = self.project_root / "å›½ä¼šè­°æ¡ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹.csv"
        self.output_dir = self.project_root / "frontend" / "public" / "data" / "legislators"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ”¿å…šåæ­£è¦åŒ–ãƒãƒƒãƒ”ãƒ³ã‚°
        self.party_mapping = {
            'è‡ªæ°‘': 'è‡ªç”±æ°‘ä¸»å…š',
            'ç«‹æ†²': 'ç«‹æ†²æ°‘ä¸»å…š', 
            'ç¶­æ–°': 'æ—¥æœ¬ç¶­æ–°ã®ä¼š',
            'å…¬æ˜': 'å…¬æ˜å…š',
            'å…±ç”£': 'æ—¥æœ¬å…±ç”£å…š',
            'æ°‘ä¸»': 'å›½æ°‘æ°‘ä¸»å…š',
            'æ²–ç¸„': 'æ²–ç¸„ã®é¢¨',
            'ã‚Œã„ã‚': 'ã‚Œã„ã‚æ–°é¸çµ„',
            'ç¤¾æ°‘': 'ç¤¾ä¼šæ°‘ä¸»å…š',
            'Nå›½': 'NHKå…š',
            'ç„¡æ‰€å±': 'ç„¡æ‰€å±'
        }
        
    def normalize_party_name(self, party_abbr: str) -> str:
        """æ”¿å…šç•¥ç§°ã‚’æ­£å¼åç§°ã«æ­£è¦åŒ–"""
        return self.party_mapping.get(party_abbr, party_abbr)
        
    def extract_birth_year(self, career_text: str) -> Optional[int]:
        """çµŒæ­´ã‹ã‚‰ç”Ÿå¹´ã‚’æŠ½å‡º (æ˜­å’Œ/å¹³æˆå¹´è¡¨è¨˜ã‹ã‚‰è¥¿æš¦å¤‰æ›)"""
        try:
            # æ˜­å’ŒXXå¹´ãƒ‘ã‚¿ãƒ¼ãƒ³
            showa_match = re.search(r'æ˜­å’Œ(\d+)å¹´', career_text)
            if showa_match:
                showa_year = int(showa_match.group(1))
                return 1925 + showa_year
                
            # å¹³æˆXXå¹´ãƒ‘ã‚¿ãƒ¼ãƒ³  
            heisei_match = re.search(r'å¹³æˆ(\d+)å¹´', career_text)
            if heisei_match:
                heisei_year = int(heisei_match.group(1))
                return 1988 + heisei_year
                
            # è¥¿æš¦ãƒ‘ã‚¿ãƒ¼ãƒ³
            year_match = re.search(r'(\d{4})å¹´', career_text)
            if year_match:
                year = int(year_match.group(1))
                if 1920 <= year <= 2010:  # å¦¥å½“ãªç”Ÿå¹´ç¯„å›²
                    return year
                    
        except (ValueError, AttributeError):
            pass
        return None
        
    def parse_election_years(self, election_str: str) -> List[int]:
        """å½“é¸å¹´æ–‡å­—åˆ—ã‹ã‚‰å¹´ã®ãƒªã‚¹ãƒˆã‚’æŠ½å‡º"""
        years = []
        try:
            # "2014ã€2016ã€2022" ã®ã‚ˆã†ãªå½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
            year_parts = re.findall(r'\d{4}', election_str)
            for year_str in year_parts:
                year = int(year_str)
                if 1950 <= year <= 2030:  # å¦¥å½“ãªå¹´ç¯„å›²
                    years.append(year)
        except (ValueError, AttributeError):
            pass
        return sorted(years)
        
    def extract_constituency_info(self, constituency: str) -> Dict[str, Any]:
        """é¸æŒ™åŒºæƒ…å ±ã‚’åˆ†æ"""
        if not constituency:
            return {"type": "unknown", "region": None}
            
        if "æ¯”ä¾‹" in constituency:
            return {"type": "proportional", "region": "å…¨å›½"}
        elif "ãƒ»" in constituency:
            # "é³¥å–ãƒ»å³¶æ ¹" ã®ã‚ˆã†ãªåˆåŒº
            return {"type": "combined", "region": constituency}
        else:
            # å˜ç‹¬çœŒ
            return {"type": "single", "region": constituency}
    
    def convert_csv_to_json(self) -> List[Dict[str, Any]]:
        """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’JSONãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›"""
        legislators = []
        
        print(f"ğŸ“‚ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {self.csv_file}")
        
        with open(self.csv_file, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            
            for idx, row in enumerate(reader, 1):
                try:
                    # åŸºæœ¬æƒ…å ±ã®æŠ½å‡º
                    name = row.get('è­°å“¡æ°å', '').strip()
                    if not name:
                        continue
                        
                    # æ”¿å…šåæ­£è¦åŒ–
                    party_abbr = row.get('ä¼šæ´¾', '').strip()
                    party_normalized = self.normalize_party_name(party_abbr)
                    
                    # é¸æŒ™åŒºæƒ…å ±ã®åˆ†æ
                    constituency_str = row.get('é¸æŒ™åŒº', '').strip()
                    constituency_info = self.extract_constituency_info(constituency_str)
                    
                    # å½“é¸å¹´ã®è§£æ
                    election_str = row.get('å½“é¸å¹´', '').strip()
                    election_years = self.parse_election_years(election_str)
                    first_election_year = election_years[0] if election_years else None
                    
                    # å½“é¸å›æ•°
                    term_count_str = row.get('å½“é¸å›æ•°', '').strip()
                    try:
                        term_count = int(term_count_str) if term_count_str.isdigit() else len(election_years)
                    except ValueError:
                        term_count = len(election_years)
                    
                    # ç”Ÿå¹´ã®æŠ½å‡º
                    career_text = row.get('çµŒæ­´', '')
                    birth_year = self.extract_birth_year(career_text)
                    
                    # ä»»æœŸæº€äº†æ—¥
                    term_end = row.get('ä»»æœŸæº€äº†', '').strip()
                    
                    # å½¹è·æƒ…å ±
                    positions = row.get('å½¹è·ç­‰', '').strip()
                    
                    # è­°å“¡ãƒ‡ãƒ¼ã‚¿ã®æ§‹ç¯‰
                    legislator = {
                        "id": f"sangiin_{idx:03d}",
                        "name": name,
                        "house": "sangiin",
                        "party": party_normalized,
                        "party_original": party_abbr,
                        "constituency": constituency_str,
                        "constituency_type": constituency_info["type"],
                        "region": constituency_info["region"],
                        "election_years": election_years,
                        "first_election_year": first_election_year,
                        "term_count": term_count,
                        "term_end": term_end,
                        "status": "active",  # ç¾è·ãƒ‡ãƒ¼ã‚¿ã¨ä»®å®š
                        "birth_year": birth_year,
                        "positions": positions,
                        "profile_url": row.get('è­°å“¡å€‹äººã®ç´¹ä»‹ãƒšãƒ¼ã‚¸', '').strip(),
                        "photo_url": row.get('å†™çœŸURL', '').strip(),
                        "reading": row.get('èª­ã¿æ–¹', '').strip(),
                        "real_name": row.get('é€šç§°åä½¿ç”¨è­°å“¡ã®æœ¬å', '').strip(),
                        "career": career_text.strip(),
                        "career_updated": row.get('çµŒæ­´ã®æ™‚ç‚¹', '').strip()
                    }
                    
                    legislators.append(legislator)
                    
                except Exception as e:
                    print(f"âš ï¸ è¡Œ{idx}ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
                    
        print(f"âœ… {len(legislators)}åã®è­°å“¡ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›å®Œäº†")
        return legislators
        
    def split_and_save(self, legislators: List[Dict[str, Any]], legislators_per_file: int = 60):
        """è­°å“¡ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ã—ã¦JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        total_legislators = len(legislators)
        file_count = (total_legislators + legislators_per_file - 1) // legislators_per_file
        
        print(f"ğŸ“ {total_legislators}åã‚’{legislators_per_file}å/ãƒ•ã‚¡ã‚¤ãƒ«ã§{file_count}ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†å‰²")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        for i in range(file_count):
            start_idx = i * legislators_per_file
            end_idx = min(start_idx + legislators_per_file, total_legislators)
            
            chunk_legislators = legislators[start_idx:end_idx]
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å: sangiin_legislators_YYYYMMDD_HHMMSS_part1.json
            filename = f"sangiin_legislators_{timestamp}_part{i+1:02d}.json"
            filepath = self.output_dir / filename
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã§JSONãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
            json_data = {
                "metadata": {
                    "house": "sangiin",
                    "data_type": "legislators",
                    "total_count": len(chunk_legislators),
                    "part_number": i + 1,
                    "total_parts": file_count,
                    "legislators_range": f"{start_idx + 1}-{end_idx}",
                    "generated_at": datetime.now().isoformat(),
                    "source_file": "å›½ä¼šè­°æ¡ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹.csv",
                    "source_url": "https://smartnews-smri.github.io/house-of-councillors/",
                    "source_attribution": "SmartNews Media Research Institute (SMRI) - House of Councillors Database",
                    "data_quality": "official_sangiin_data",
                    "license": "Please refer to the original source for license information"
                },
                "data": chunk_legislators
            }
            
            # JSONãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
                
            file_size = filepath.stat().st_size / (1024 * 1024)
            print(f"ğŸ’¾ {filename}: {len(chunk_legislators)}å ({file_size:.1f} MB)")
            
        # çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ä½œæˆ
        unified_filename = f"sangiin_legislators_unified_{timestamp}.json"
        unified_filepath = self.output_dir / unified_filename
        
        unified_data = {
            "metadata": {
                "house": "sangiin", 
                "data_type": "legislators_unified",
                "total_count": total_legislators,
                "total_parts": file_count,
                "generated_at": datetime.now().isoformat(),
                "source_file": "å›½ä¼šè­°æ¡ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹.csv",
                "source_url": "https://smartnews-smri.github.io/house-of-councillors/",
                "source_attribution": "SmartNews Media Research Institute (SMRI) - House of Councillors Database",
                "data_quality": "official_sangiin_data",
                "license": "Please refer to the original source for license information"
            },
            "data": legislators
        }
        
        with open(unified_filepath, 'w', encoding='utf-8') as f:
            json.dump(unified_data, f, ensure_ascii=False, indent=2)
            
        unified_size = unified_filepath.stat().st_size / (1024 * 1024)
        print(f"ğŸ“š çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«: {unified_filename} ({unified_size:.1f} MB)")
        
    def generate_summary_stats(self, legislators: List[Dict[str, Any]]):
        """è­°å“¡ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        print("\nğŸ“Š å‚è­°é™¢è­°å“¡ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
        print(f"ç·è­°å“¡æ•°: {len(legislators)}å")
        
        # æ”¿å…šåˆ¥é›†è¨ˆ
        party_counts = {}
        for leg in legislators:
            party = leg['party']
            party_counts[party] = party_counts.get(party, 0) + 1
            
        print("\nğŸ›ï¸ æ”¿å…šåˆ¥è­°å“¡æ•°:")
        for party, count in sorted(party_counts.items(), key=lambda x: x[1], reverse=True):
            print(f"  {party}: {count}å")
            
        # é¸æŒ™åŒºã‚¿ã‚¤ãƒ—åˆ¥é›†è¨ˆ
        constituency_types = {}
        for leg in legislators:
            const_type = leg['constituency_type']
            constituency_types[const_type] = constituency_types.get(const_type, 0) + 1
            
        print("\nğŸ—³ï¸ é¸æŒ™åŒºã‚¿ã‚¤ãƒ—åˆ¥:")
        for const_type, count in constituency_types.items():
            print(f"  {const_type}: {count}å")

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("ğŸš€ å‚è­°é™¢è­°å“¡CSVâ†’JSONå¤‰æ›é–‹å§‹")
    
    converter = SangiinCSVConverter()
    
    # CSVå­˜åœ¨ç¢ºèª
    if not converter.csv_file.exists():
        print(f"âŒ CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {converter.csv_file}")
        return
        
    # CSVâ†’JSONå¤‰æ›
    legislators = converter.convert_csv_to_json()
    
    if not legislators:
        print("âŒ è­°å“¡ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return
        
    # çµ±è¨ˆè¡¨ç¤º
    converter.generate_summary_stats(legislators)
    
    # åˆ†å‰²ä¿å­˜
    converter.split_and_save(legislators)
    
    print("\nâœ¨ å‚è­°é™¢è­°å“¡JSONå¤‰æ›å®Œäº†!")

if __name__ == "__main__":
    main()