#!/usr/bin/env python3
"""
æå‡ºæ³•æ¡ˆåé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ãƒ™ãƒ¼ã‚¹ç‰ˆï¼‰

è¡†è­°é™¢è­°æ¡ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã«åŸºã¥ã„ãŸåŠ¹ç‡çš„ãªåé›†
https://www.shugiin.go.jp/internet/itdb_gian.nsf/html/gian/kaiji217.htm
å®Ÿéš›ã®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã‚’è§£æã—ã¦æ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
"""

import json
import requests
import time
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
from fake_useragent import UserAgent
from bs4 import BeautifulSoup
import logging
import random
from urllib.parse import urljoin

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class BillsTableCollector:
    """æå‡ºæ³•æ¡ˆåé›†ã‚¯ãƒ©ã‚¹ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ãƒ™ãƒ¼ã‚¹ç‰ˆï¼‰"""
    
    def __init__(self, max_bills: int = 50):
        self.ua = UserAgent()
        self.session = requests.Session()
        self.update_headers()
        
        # åé›†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.max_bills = max_bills
        
        # å¯¾è±¡ã¨ãªã‚‹å›½ä¼šå›æ¬¡
        self.target_sessions = [217, 216, 215]
        
        logger.info(f"æœ€å¤§åé›†ä»¶æ•°: {self.max_bills}ä»¶")
        logger.info(f"å¯¾è±¡å›½ä¼š: {', '.join(f'ç¬¬{s}å›' for s in self.target_sessions)}")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        self.project_root = Path(__file__).parent.parent.parent
        self.bills_dir = self.project_root / "data" / "processed" / "bills"
        self.frontend_bills_dir = self.project_root / "frontend" / "public" / "data" / "bills"
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.bills_dir.mkdir(parents=True, exist_ok=True)
        self.frontend_bills_dir.mkdir(parents=True, exist_ok=True)
        
        # åŸºæœ¬URLè¨­å®š
        self.base_url = "https://www.shugiin.go.jp"
        
    def update_headers(self):
        """User-Agentæ›´æ–°ã¨IPå½è£…"""
        self.session.headers.update({
            'User-Agent': self.ua.random,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.7,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0'
        })
    
    def random_delay(self, min_seconds=1, max_seconds=3):
        """ãƒ©ãƒ³ãƒ€ãƒ é…å»¶ã§ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ"""
        delay = random.uniform(min_seconds, max_seconds)
        time.sleep(delay)
    
    def build_absolute_url(self, href: str, base_page_url: str) -> Optional[str]:
        """ç›¸å¯¾URLã‚’çµ¶å¯¾URLã«å¤‰æ›"""
        if not href or href.strip() == '':
            return None
        
        # ç›¸å¯¾URLå‡¦ç†
        if href.startswith('./'):
            # ./keika/1DDDDAA.htm -> https://www.shugiin.go.jp/internet/itdb_gian.nsf/html/gian/keika/1DDDDAA.htm
            relative_path = href[2:]
            base_dir = '/'.join(base_page_url.split('/')[:-1])
            return f"{base_dir}/{relative_path}"
        
        elif href.startswith('/'):
            # çµ¶å¯¾ãƒ‘ã‚¹
            return f"{self.base_url}{href}"
        
        else:
            # ç›¸å¯¾ãƒ‘ã‚¹
            base_dir = '/'.join(base_page_url.split('/')[:-1])
            return f"{base_dir}/{href}"
    
    def collect_bills_from_session(self, session_number: int) -> List[Dict[str, Any]]:
        """ç‰¹å®šã®å›½ä¼šã‹ã‚‰ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ™ãƒ¼ã‚¹ã§è­°æ¡ˆã‚’åé›†"""
        bills = []
        
        try:
            # å›½ä¼šåˆ¥è­°æ¡ˆä¸€è¦§ãƒšãƒ¼ã‚¸URL
            session_url = f"{self.base_url}/internet/itdb_gian.nsf/html/gian/kaiji{session_number}.htm"
            
            self.update_headers()
            self.random_delay()
            
            response = self.session.get(session_url, timeout=30)
            response.raise_for_status()
            response.encoding = 'shift_jis'
            
            soup = BeautifulSoup(response.text, 'html.parser')
            logger.info(f"ç¬¬{session_number}å›å›½ä¼šãƒšãƒ¼ã‚¸å–å¾—æˆåŠŸ: {session_url}")
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‚’æŠ½å‡º
            table_rows = self.extract_table_rows(soup)
            logger.info(f"ç™ºè¦‹ã—ãŸãƒ†ãƒ¼ãƒ–ãƒ«è¡Œæ•°: {len(table_rows)}")
            
            # å„è¡Œã‹ã‚‰è­°æ¡ˆæƒ…å ±ã‚’æŠ½å‡º
            collected_count = 0
            for idx, row in enumerate(table_rows):
                if collected_count >= self.max_bills // len(self.target_sessions):
                    logger.info(f"ç¬¬{session_number}å›å›½ä¼šã®åé›†ä¸Šé™ã«åˆ°é”")
                    break
                
                try:
                    bill_info = self.extract_bill_from_row(row, session_url, session_number)
                    if bill_info and self.validate_bill_data(bill_info):
                        bills.append(bill_info)
                        collected_count += 1
                        logger.info(f"è­°æ¡ˆå–å¾—æˆåŠŸ ({collected_count}): {bill_info['title'][:50]}...")
                    
                except Exception as e:
                        logger.error(f"è¡Œã®è§£æã‚¨ãƒ©ãƒ¼ ({idx+1}): {str(e)}")
                        continue
            
            return bills
            
        except Exception as e:
            logger.error(f"ç¬¬{session_number}å›å›½ä¼šã®è­°æ¡ˆåé›†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def extract_table_rows(self, soup: BeautifulSoup) -> List:
        """ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‚’æŠ½å‡º"""
        try:
            # trã‚¿ã‚°ã§ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‚’æ¤œç´¢
            rows = soup.find_all('tr', {'valign': 'top'})
            
            # ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹è¡Œã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            valid_rows = []
            for row in rows:
                cells = row.find_all('td')
                if len(cells) >= 6:  # 6åˆ—ï¼ˆå›æ¬¡ã€ç•ªå·ã€ã‚¿ã‚¤ãƒˆãƒ«ã€çŠ¶æ³ã€çµŒéã€æœ¬æ–‡ï¼‰
                    # æœ€åˆã®ã‚»ãƒ«ãŒæ•°å­—ï¼ˆå›½ä¼šå›æ¬¡ï¼‰ã‹ãƒã‚§ãƒƒã‚¯
                    first_cell_text = cells[0].get_text(strip=True)
                    if first_cell_text.isdigit():
                        valid_rows.append(row)
            
            logger.info(f"æœ‰åŠ¹ãªãƒ†ãƒ¼ãƒ–ãƒ«è¡Œ: {len(valid_rows)}ä»¶")
            return valid_rows
            
        except Exception as e:
            logger.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«è¡ŒæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def extract_bill_from_row(self, row, base_url: str, session_number: int) -> Optional[Dict[str, Any]]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«è¡Œã‹ã‚‰è­°æ¡ˆæƒ…å ±ã‚’æŠ½å‡º"""
        try:
            cells = row.find_all('td')
            if len(cells) < 6:
                return None
            
            # ã‚»ãƒ«ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
            # cells[0]: å›½ä¼šå›æ¬¡
            # cells[1]: è­°æ¡ˆç•ªå·
            # cells[2]: è­°æ¡ˆå
            # cells[3]: çŠ¶æ³
            # cells[4]: çµŒéãƒªãƒ³ã‚¯
            # cells[5]: æœ¬æ–‡ãƒªãƒ³ã‚¯
            
            diet_session = cells[0].get_text(strip=True)
            bill_number = cells[1].get_text(strip=True)
            title = cells[2].get_text(strip=True)
            status = cells[3].get_text(strip=True)
            
            # çµŒéãƒªãƒ³ã‚¯ã‚’å–å¾—
            progress_link = None
            progress_a = cells[4].find('a')
            if progress_a and progress_a.get('href'):
                progress_link = self.build_absolute_url(progress_a.get('href'), base_url)
            
            # æœ¬æ–‡ãƒªãƒ³ã‚¯ã‚’å–å¾—
            content_link = None
            content_a = cells[5].find('a')
            if content_a and content_a.get('href'):
                content_link = self.build_absolute_url(content_a.get('href'), base_url)
            
            # ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
            if not title or len(title) < 5:
                return None
            
            # è­°æ¡ˆæƒ…å ±ã‚’æ§‹ç¯‰
            bill_info = {
                'title': title,
                'bill_number': bill_number,
                'session_number': int(diet_session) if diet_session.isdigit() else session_number,
                'url': content_link or progress_link,
                'content_url': content_link,
                'progress_url': progress_link,
                'submitter': self.infer_submitter(title),
                'submission_date': '',  # ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¯å«ã¾ã‚Œã¦ã„ãªã„
                'status': status,
                'status_normalized': self.normalize_status(status),
                'committee': '',  # ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã¯å«ã¾ã‚Œã¦ã„ãªã„
                'bill_content': '',  # å¾Œã§æœ¬æ–‡ãƒªãƒ³ã‚¯ã‹ã‚‰å–å¾—å¯èƒ½
                'related_links': [
                    {'url': content_link, 'title': 'æœ¬æ–‡'} if content_link else None,
                    {'url': progress_link, 'title': 'çµŒé'} if progress_link else None
                ],
                'summary': self.generate_summary(title),
                'category': self.classify_bill_category(title),
                'collected_at': datetime.now().isoformat(),
                'year': datetime.now().year
            }
            
            # Noneã‚’é™¤å»
            bill_info['related_links'] = [link for link in bill_info['related_links'] if link]
            
            return bill_info
            
        except Exception as e:
            logger.error(f"è¡Œã‹ã‚‰ã®è­°æ¡ˆæŠ½å‡ºã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
    
    def infer_submitter(self, title: str) -> str:
        """è­°æ¡ˆã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æå‡ºè€…ã‚’æ¨æ¸¬"""
        # ä¸€èˆ¬çš„ã«å†…é–£æå‡ºæ³•æ¡ˆãŒå¤šã„
        if any(keyword in title for keyword in ['ç¨', 'äºˆç®—', 'è¡Œæ”¿', 'æ”¹æ­£', 'è¨­ç½®', 'å»ƒæ­¢']):
            return 'å†…é–£'
        else:
            return 'è­°å“¡'
    
    def normalize_status(self, status: str) -> str:
        """è­°æ¡ˆçŠ¶æ³ã‚’æ­£è¦åŒ–"""
        status_mapping = {
            'å¯æ±º': 'å¯æ±º',
            'æˆç«‹': 'æˆç«‹',
            'å¦æ±º': 'å¦æ±º',
            'å»ƒæ¡ˆ': 'å»ƒæ¡ˆ',
            'æ’¤å›': 'æ’¤å›',
            'ç¶™ç¶šå¯©è­°': 'ç¶™ç¶šå¯©è­°',
            'å¯©è­°ä¸­': 'å¯©è­°ä¸­',
            'è¡†è­°é™¢ã§å¯©è­°ä¸­': 'å¯©è­°ä¸­',
            'å‚è­°é™¢ã§å¯©è­°ä¸­': 'å¯©è­°ä¸­',
            'è¡†è­°é™¢ã§é–‰ä¼šä¸­å¯©æŸ»': 'ç¶™ç¶šå¯©è­°',
            'å‚è­°é™¢ã§é–‰ä¼šä¸­å¯©æŸ»': 'ç¶™ç¶šå¯©è­°'
        }
        
        for key, value in status_mapping.items():
            if key in status:
                return value
        
        return 'ä¸æ˜'
    
    def generate_summary(self, title: str) -> str:
        """è­°æ¡ˆã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        try:
            if len(title) > 100:
                return title[:100] + "..."
            else:
                return title
            
        except Exception as e:
            logger.error(f"ã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return title
    
    def classify_bill_category(self, title: str) -> str:
        """è­°æ¡ˆã‚«ãƒ†ã‚´ãƒªã‚’åˆ†é¡"""
        categories = {
            'å¤–äº¤ãƒ»å®‰å…¨ä¿éšœ': ['å¤–äº¤', 'æ¡ç´„', 'é˜²è¡›', 'è‡ªè¡›éšŠ', 'å®‰å…¨ä¿éšœ', 'æ—¥ç±³'],
            'çµŒæ¸ˆãƒ»è²¡æ”¿': ['çµŒæ¸ˆ', 'è²¡æ”¿', 'äºˆç®—', 'ç¨åˆ¶', 'é‡‘è', 'ç”£æ¥­', 'ç¨', 'é–¢ç¨'],
            'ç¤¾ä¼šä¿éšœ': ['å¹´é‡‘', 'åŒ»ç™‚', 'ä»‹è­·', 'ç¦ç¥‰', 'ç¤¾ä¼šä¿éšœ', 'å¥åº·ä¿é™º'],
            'æ•™è‚²ãƒ»æ–‡åŒ–': ['æ•™è‚²', 'å­¦æ ¡', 'å¤§å­¦', 'æ–‡åŒ–', 'æ–‡éƒ¨ç§‘å­¦', 'ã‚¹ãƒãƒ¼ãƒ„'],
            'ç’°å¢ƒãƒ»ã‚¨ãƒãƒ«ã‚®ãƒ¼': ['ç’°å¢ƒ', 'ã‚¨ãƒãƒ«ã‚®ãƒ¼', 'åŸå­åŠ›', 'å†ç”Ÿå¯èƒ½', 'æ°—å€™'],
            'åŠ´åƒãƒ»é›‡ç”¨': ['åŠ´åƒ', 'é›‡ç”¨', 'åƒãæ–¹', 'è³ƒé‡‘', 'è·æ¥­'],
            'å¸æ³•ãƒ»è¡Œæ”¿': ['å¸æ³•', 'è¡Œæ”¿', 'å…¬å‹™å“¡', 'è£åˆ¤', 'æ³•å‹™', 'æ‰‹ç¶š'],
            'åœ°æ–¹ãƒ»éƒ½å¸‚': ['åœ°æ–¹', 'è‡ªæ²»ä½“', 'éƒ½å¸‚', 'å¸‚ç”ºæ‘', 'åœ°åŸŸ'],
            'äº¤é€šãƒ»å›½åœŸ': ['äº¤é€š', 'é“è·¯', 'å›½åœŸ', 'é‰„é“', 'èˆªç©º', 'æ¸¯æ¹¾'],
            'ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ»IT': ['ãƒ‡ã‚¸ã‚¿ãƒ«', 'IT', 'æƒ…å ±', 'ãƒã‚¤ãƒŠãƒ³ãƒãƒ¼', 'ç•ªå·']
        }
        
        title_lower = title.lower()
        
        for category, keywords in categories.items():
            if any(keyword in title_lower for keyword in keywords):
                return category
        
        return 'ä¸€èˆ¬'
    
    def validate_bill_data(self, bill: Dict[str, Any]) -> bool:
        """è­°æ¡ˆãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ãƒã‚§ãƒƒã‚¯
        if not bill.get('title') or not bill.get('bill_number'):
            return False
        
        # ã‚¿ã‚¤ãƒˆãƒ«ãŒæ„å‘³ã®ã‚ã‚‹ã‚‚ã®ã‹ãƒã‚§ãƒƒã‚¯
        title = bill.get('title', '')
        if len(title) < 5:
            return False
        
        # URLã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆå°‘ãªãã¨ã‚‚1ã¤ã¯å¿…è¦ï¼‰
        if not bill.get('url') and not bill.get('content_url') and not bill.get('progress_url'):
            return False
        
        return True
    
    def collect_all_bills(self) -> List[Dict[str, Any]]:
        """ã™ã¹ã¦ã®è­°æ¡ˆã‚’åé›†"""
        logger.info("æå‡ºæ³•æ¡ˆåé›†é–‹å§‹...")
        all_bills = []
        seen_bills = set()  # é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨
        
        try:
            for session in self.target_sessions:
                if len(all_bills) >= self.max_bills:
                    logger.info(f"æœ€å¤§åé›†ä»¶æ•°({self.max_bills})ã«åˆ°é”ã—ã¾ã—ãŸ")
                    break
                
                session_bills = self.collect_bills_from_session(session)
                
                # é‡è¤‡é™¤å»å‡¦ç†
                unique_bills = []
                for bill in session_bills:
                    # æ³•æ¡ˆã®ä¸€æ„æ€§ã‚’åˆ¤å®šã™ã‚‹ã‚­ãƒ¼ï¼ˆã‚¿ã‚¤ãƒˆãƒ« + æ³•æ¡ˆç•ªå·ï¼‰
                    bill_key = f"{bill.get('title', '')}#{bill.get('bill_number', '')}#{bill.get('submitter', '')}"
                    
                    if bill_key not in seen_bills:
                        seen_bills.add(bill_key)
                        unique_bills.append(bill)
                    else:
                        logger.debug(f"é‡è¤‡æ³•æ¡ˆã‚’ã‚¹ã‚­ãƒƒãƒ—: {bill.get('title', '')[:50]}...")
                
                all_bills.extend(unique_bills)
                logger.info(f"ç¬¬{session}å›å›½ä¼šã‹ã‚‰{len(unique_bills)}ä»¶ã®è­°æ¡ˆã‚’åé›†ï¼ˆé‡è¤‡é™¤å»å¾Œï¼‰")
            
            logger.info(f"æå‡ºæ³•æ¡ˆåé›†å®Œäº†: {len(all_bills)}ä»¶ï¼ˆé‡è¤‡é™¤å»æ¸ˆã¿ï¼‰")
            return all_bills
            
        except Exception as e:
            logger.error(f"æå‡ºæ³•æ¡ˆåé›†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return []
    
    def save_bills_data(self, bills: List[Dict[str, Any]]):
        """è­°æ¡ˆãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜"""
        if not bills:
            logger.warning("ä¿å­˜ã™ã‚‹è­°æ¡ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return
        
        current_date = datetime.now()
        data_period = current_date.strftime('%Y%m%d')
        timestamp = current_date.strftime('%H%M%S')
        
        data_structure = {
            "metadata": {
                "data_type": "shugiin_bills_table_based",
                "collection_method": "table_extraction",
                "total_bills": len(bills),
                "generated_at": current_date.isoformat(),
                "source_site": "www.shugiin.go.jp",
                "target_sessions": self.target_sessions,
                "data_quality": "table_based_collection",
                "version": "3.0"
            },
            "data": bills
        }
        
        # ç”Ÿãƒ‡ãƒ¼ã‚¿ä¿å­˜
        raw_filename = f"bills_{data_period}_{timestamp}.json"
        raw_filepath = self.bills_dir / raw_filename
        
        with open(raw_filepath, 'w', encoding='utf-8') as f:
            json.dump(data_structure, f, ensure_ascii=False, indent=2)
        
        # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        frontend_filename = f"bills_{data_period}_{timestamp}.json"
        frontend_filepath = self.frontend_bills_dir / frontend_filename
        
        with open(frontend_filepath, 'w', encoding='utf-8') as f:
            json.dump(data_structure, f, ensure_ascii=False, indent=2)
        
        # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°
        latest_file = self.frontend_bills_dir / "bills_latest.json"
        with open(latest_file, 'w', encoding='utf-8') as f:
            json.dump(data_structure, f, ensure_ascii=False, indent=2)
        logger.info(f"ğŸ“ æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°: {latest_file}")
        
        logger.info(f"è­°æ¡ˆãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†:")
        logger.info(f"  - ç”Ÿãƒ‡ãƒ¼ã‚¿: {raw_filepath}")
        logger.info(f"  - ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰: {frontend_filepath}")
        logger.info(f"  - ä»¶æ•°: {len(bills)}")
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆ
        logger.info("ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆ:")
        logger.info(f"  - æœ‰åŠ¹URLä»˜ãè­°æ¡ˆ: {sum(1 for b in bills if b.get('url'))}ä»¶")
        logger.info(f"  - æœ¬æ–‡ãƒªãƒ³ã‚¯ä»˜ãè­°æ¡ˆ: {sum(1 for b in bills if b.get('content_url'))}ä»¶")
        logger.info(f"  - çµŒéãƒªãƒ³ã‚¯ä»˜ãè­°æ¡ˆ: {sum(1 for b in bills if b.get('progress_url'))}ä»¶")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æå‡ºæ³•æ¡ˆåé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ãƒ™ãƒ¼ã‚¹ç‰ˆï¼‰')
    parser.add_argument('--max-bills', type=int, default=50, help='æœ€å¤§åé›†ä»¶æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ä»¶)')
    
    args = parser.parse_args()
    
    collector = BillsTableCollector(max_bills=args.max_bills)
    
    try:
        # æå‡ºæ³•æ¡ˆåé›†
        bills = collector.collect_all_bills()
        
        if bills:
            # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            collector.save_bills_data(bills)
            logger.info(f"æ–°è¦æå‡ºæ³•æ¡ˆåé›†å®Œäº†: {len(bills)}ä»¶")
        else:
            logger.info("æ–°è¦æå‡ºæ³•æ¡ˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
    except Exception as e:
        logger.error(f"ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
        raise

if __name__ == "__main__":
    main()