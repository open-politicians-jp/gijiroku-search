#!/usr/bin/env python3
"""
æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚° - ç„¡åŠ¹ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨é™¤å»
"""

import json
import logging
from datetime import datetime
from pathlib import Path

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def clean_candidate_data():
    """å€™è£œè€…ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç„¡åŠ¹ãªã‚¨ãƒ³ãƒˆãƒªã‚’å®Œå…¨ã«é™¤å»"""
    logger.info("ğŸ§¹ å€™è£œè€…ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹...")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    data_dir = Path(__file__).parent.parent.parent / "frontend" / "public" / "data" / "sangiin_candidates"
    
    # æ—¢å­˜ã®é¸æŒ™åŒºãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆæ¯”ä¾‹ä»£è¡¨ã¯é™¤å¤–ï¼‰
    for file_path in data_dir.glob("go2senkyo_*.json"):
        if "latest" in file_path.name:
            continue
        
        logger.info(f"ğŸ“‚ å‡¦ç†ä¸­: {file_path.name}")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        original_count = len(data.get('data', []))
        logger.info(f"  å…ƒãƒ‡ãƒ¼ã‚¿: {original_count}å")
        
        # ç„¡åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        valid_candidates = []
        invalid_names = [
            'ä¼šå“¡ç™»éŒ²', 'æ¯”ä¾‹ä»£è¡¨äºˆæƒ³', 'ãƒ­ã‚°ã‚¤ãƒ³', 'ã‚µã‚¤ãƒ³ã‚¢ãƒƒãƒ—', 
            'MYé¸æŒ™', 'é¸æŒ™åŒº', 'ã“ã®', 'ã‚³ãƒ³ãƒ†ãƒ³ãƒ„', 'äºˆæƒ³ã•ã‚Œã‚‹é¡”ã¶ã‚Œ',
            'ã«ã¤ã„ã¦', 'ã‚·ã‚§ã‚¢', 'ãƒšãƒ¼ã‚¸', 'æ”¿å…š', 'å…¨æ”¿å…š',
            'è‡ªç”±æ°‘ä¸»å…š', 'ç«‹æ†²æ°‘ä¸»å…š', 'å…¬æ˜å…š', 'æ—¥æœ¬ç¶­æ–°ã®ä¼š', 'æ—¥æœ¬å…±ç”£å…š',
            'å›½æ°‘æ°‘ä¸»å…š', 'ã‚Œã„ã‚æ–°é¸çµ„', 'å‚æ”¿å…š', 'ç¤¾ä¼šæ°‘ä¸»å…š', 
            'æ—¥æœ¬ä¿å®ˆå…š', 'ã¿ã‚“ãªã§ã¤ãã‚‹å…š', 'NHKå…š', 'ãƒãƒ¼ãƒ ã¿ã‚‰ã„',
            'å†ç”Ÿã®é“', 'æ—¥æœ¬æ”¹é©å…š', 'ç„¡æ‰€å±é€£åˆ', 'æ—¥æœ¬èª çœŸä¼š',
            'æ¯”ä¾‹ä»£è¡¨', 'å…¨å›½æ¯”ä¾‹', 'ä»£è¡¨è€…', 'ç™¾ç”°å°šæ¨¹', 'çŸ³æ¿±å“²ä¿¡',
            'ã“ã®ãƒšãƒ¼ã‚¸', 'ã‚’ã‚·ã‚§ã‚¢', 'ã™ã‚‹', 'ã“ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„'
        ]
        
        for candidate in data.get('data', []):
            name = candidate.get('name', '')
            
            # åŸºæœ¬çš„ãªãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            if len(name) < 2 or len(name) > 10:
                logger.debug(f"  é™¤å¤–(é•·ã•): {name}")
                continue
            
            # ç„¡åŠ¹åã®ãƒã‚§ãƒƒã‚¯
            if any(invalid in name for invalid in invalid_names):
                logger.debug(f"  é™¤å¤–(ç„¡åŠ¹å): {name}")
                continue
            
            # æ¼¢å­—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if not any(ord(char) >= 0x4e00 and ord(char) <= 0x9fff for char in name):
                logger.debug(f"  é™¤å¤–(æ¼¢å­—ãªã—): {name}")
                continue
            
            # é¸æŒ™åŒºå€™è£œè€…ã®ã¿ï¼ˆæ¯”ä¾‹ä»£è¡¨ã‚’é™¤å¤–ï¼‰
            if candidate.get('constituency_type') == 'proportional':
                logger.debug(f"  é™¤å¤–(æ¯”ä¾‹ä»£è¡¨): {name}")
                continue
            
            # éƒ½é“åºœçœŒãŒæ­£å¸¸ã‹ãƒã‚§ãƒƒã‚¯
            prefecture = candidate.get('prefecture', '')
            if not prefecture or prefecture in ['æ¯”ä¾‹ä»£è¡¨', 'å…¨å›½æ¯”ä¾‹']:
                logger.debug(f"  é™¤å¤–(éƒ½é“åºœçœŒç„¡åŠ¹): {name} - {prefecture}")
                continue
            
            valid_candidates.append(candidate)
        
        logger.info(f"  æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿: {len(valid_candidates)}å")
        logger.info(f"  é™¤å»æ•°: {original_count - len(valid_candidates)}å")
        
        # çµ±è¨ˆã‚’å†è¨ˆç®—
        party_stats = {}
        prefecture_stats = {}
        
        for candidate in valid_candidates:
            party = candidate.get('party', 'ç„¡æ‰€å±')
            prefecture = candidate.get('prefecture', 'æœªåˆ†é¡')
            
            party_stats[party] = party_stats.get(party, 0) + 1
            prefecture_stats[prefecture] = prefecture_stats.get(prefecture, 0) + 1
        
        # ãƒ‡ãƒ¼ã‚¿æ›´æ–°
        data['data'] = valid_candidates
        data['metadata']['total_candidates'] = len(valid_candidates)
        data['metadata']['data_type'] = "go2senkyo_clean_sangiin_2025"
        data['metadata']['collection_method'] = "constituency_only_cleaned"
        data['metadata']['generated_at'] = datetime.now().isoformat()
        
        data['statistics'] = {
            "by_party": party_stats,
            "by_prefecture": prefecture_stats,
            "by_constituency_type": {"single_member": len(valid_candidates)}
        }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… æ›´æ–°å®Œäº†: {file_path.name}")
    
    # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚æ›´æ–°
    clean_latest_file(data_dir, valid_candidates, party_stats, prefecture_stats)

def clean_latest_file(data_dir, valid_candidates, party_stats, prefecture_stats):
    """æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿ã§æ›´æ–°"""
    
    latest_file = data_dir / "go2senkyo_optimized_latest.json"
    
    clean_data = {
        "metadata": {
            "data_type": "go2senkyo_clean_sangiin_2025",
            "collection_method": "constituency_only_cleaned",
            "total_candidates": len(valid_candidates),
            "generated_at": datetime.now().isoformat(),
            "source_site": "sangiin.go2senkyo.com",
            "coverage": {
                "constituency_types": 1,
                "parties": len(party_stats),
                "prefectures": len(prefecture_stats)
            },
            "collection_stats": {
                "total_candidates": len(valid_candidates),
                "detailed_profiles": 0,
                "with_photos": 0,
                "with_policies": 0,
                "errors": 0
            },
            "quality_metrics": {
                "detail_coverage": "0%",
                "photo_coverage": "0%",
                "policy_coverage": "0%"
            }
        },
        "statistics": {
            "by_party": party_stats,
            "by_prefecture": prefecture_stats,
            "by_constituency_type": {"single_member": len(valid_candidates)}
        },
        "data": valid_candidates
    }
    
    with open(latest_file, 'w', encoding='utf-8') as f:
        json.dump(clean_data, f, ensure_ascii=False, indent=2)
    
    logger.info(f"ğŸ“ æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°: {latest_file}")
    logger.info(f"ğŸ¯ æœ€çµ‚çµæœ:")
    logger.info(f"  ç·å€™è£œè€…æ•°: {len(valid_candidates)}å")
    logger.info(f"  æ”¿å…šæ•°: {len(party_stats)}æ”¿å…š")
    logger.info(f"  éƒ½é“åºœçœŒæ•°: {len(prefecture_stats)}éƒ½é“åºœçœŒ")
    
    # çµ±è¨ˆè¡¨ç¤º
    logger.info("ğŸ“Š æ”¿å…šåˆ¥çµ±è¨ˆï¼ˆä¸Šä½10ï¼‰:")
    top_parties = sorted(party_stats.items(), key=lambda x: x[1], reverse=True)[:10]
    for party, count in top_parties:
        logger.info(f"  {party}: {count}å")

if __name__ == "__main__":
    clean_candidate_data()